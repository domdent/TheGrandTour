{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dom\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sklearn\n",
    "\n",
    "\n",
    "readdata = pd.read_csv(\"C:/Users/Dom/MPhys/TheGrandTour/wine_data.txt\", sep=\"\\t\", header=None);\n",
    "data = np.array(readdata);\n",
    "data = np.delete(data, 0, 0)\n",
    "data = data.astype(float)\n",
    "data = np.swapaxes(data,0,1)\n",
    "\n",
    "\n",
    "# Need to seperate the classification dimension:\n",
    "classification = data[13]\n",
    "data = np.delete(data, 13, axis=0)\n",
    "\n",
    "\n",
    "# make list of colours for each number:\n",
    "data_colour = []\n",
    "for i in range(len(classification)):\n",
    "    if classification[i] == 1:\n",
    "        data_colour.append(\"r\")\n",
    "    elif classification[i] == 2:\n",
    "        data_colour.append(\"b\")\n",
    "    elif classification[i] == 3:\n",
    "        data_colour.append(\"g\")\n",
    "        \n",
    "# Normalizes the data        \n",
    "for i in range(0, np.shape(data)[0]):\n",
    "    data[i,:] = (data[i,:] / np.ndarray.max(data[i,:])) * 2 - 1\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "#VARIABLES\n",
    "stepSize = 0.01\n",
    "nSteps = 10000\n",
    "\n",
    "def getAlpha(d):\n",
    "    \"\"\"\n",
    "    NEEDS IMPLEMENTATION\n",
    "    Should produce 1xd(d-1)/2 array of position in grand tour.\n",
    "    \"\"\"\n",
    "    p = d*(d-1)/2     \n",
    "    primeList = []\n",
    "    count = 1\n",
    "    while len(primeList) < p:\n",
    "        count += 1\n",
    "        primeBool = False\n",
    "        for i in range(2, count - 1):\n",
    "            if count % i == 0:\n",
    "                primeBool = True\n",
    "        if primeBool == False:\n",
    "            irrational = (np.sqrt(count)%1)\n",
    "            primeList.append(irrational)\n",
    "            \n",
    "    primeList = np.asarray(primeList)\n",
    "    primeList = primeList.dot(stepSize)\n",
    "    \"\"\"\n",
    "    Irrational number generation using exponentials, not being used\n",
    "    p = int(d*(d-1)/2)\n",
    "    alpha = np.zeros(p) #alpha(t) parameters defining grand tour in G2,d\n",
    "    for i in range(0,p):\n",
    "        alpha[i] = (np.exp(i) % 1) * 2 * np.pi\n",
    "        \n",
    "    alpha = alpha.dot(0.001)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return primeList\n",
    "\n",
    "\n",
    "def getAngles(alpha,d):\n",
    "    \"\"\"\"\"\n",
    "    Inputs: \n",
    "    alpha = 1xd(d-1)/2 array defining position on grand tour\n",
    "    d = dimensions of data\n",
    "    Outputs a dxd array of angles required for the transformation\n",
    "    \"\"\"\n",
    "    theta = np.zeros((d,d));\n",
    "    i = 0;\n",
    "    k = 0;\n",
    "    \n",
    "    while i < d-1:\n",
    "        j = i + 1;\n",
    "        \n",
    "        while j < d:\n",
    "            theta[i][j] = alpha[k];\n",
    "            j += 1;\n",
    "            k += 1;\n",
    "    \n",
    "        i+= 1;\n",
    "        \n",
    "    return theta;\n",
    "\n",
    "\n",
    "def RotationMatrix(i, j, d, theta):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    i = first indicie of rotating plane\n",
    "    j = second indicie of rotating plane\n",
    "    d = dimensions of data\n",
    "    theta = dxd array of angle of rotation of rotating plane\n",
    "    Outputs a rotating matrix to rotate plane of ixj plane by theta_ij\n",
    "    \"\"\"\n",
    "    R = np.identity(d)\n",
    "    R[i,i] = np.cos(theta)\n",
    "    R[i,j] = -1*np.sin(theta)\n",
    "    R[j,i] = np.sin(theta)\n",
    "    R[j,j] = np.cos(theta)\n",
    "    return R\n",
    "\n",
    "\n",
    "def BetaFn(d, theta):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    d = dimensions of data\n",
    "    theta = dxd array of angle of rotation ixj plane\n",
    "    Outputs the full matrix transformation for all rotations\n",
    "    \"\"\"\n",
    "    b = RotationMatrix(1, 2, d, theta[1,2])\n",
    "    i = 1\n",
    "    j = 2\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            if i==1 and j==2:\n",
    "                continue\n",
    "            b = np.matmul(b, RotationMatrix(i, j, d, theta[i,j]))\n",
    "            \n",
    "    return b\n",
    "\n",
    "\n",
    "def GrandTour(data, nSteps):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    data = array of data points, dimensions x npoints\n",
    "    Outputs a 3D array number of points x t x dimensions, where t\n",
    "    the time step at that point in the tour\n",
    "    \"\"\"\n",
    "\n",
    "    d = np.shape(data)[0] #dimensions of data\n",
    "    nPoints = np.shape(data)[1] #number of data points\n",
    "    tData = np.zeros((nSteps,d,nPoints)) #initialise 3d matrix to store stransforemd data at each timestep\n",
    "    tBeta = np.zeros((nSteps,d,d))\n",
    "    Alpha = getAlpha(d)\n",
    "\n",
    "    \n",
    "    for t in range(0, nSteps):\n",
    "        \n",
    "        \n",
    "        alpha = Alpha.dot(t)\n",
    "        theta = getAngles(alpha, d)\n",
    "        b = BetaFn(d, theta)\n",
    "        a = np.matmul(b, data)\n",
    "        tData[t,:,:] = a\n",
    "        tBeta[t,:,:] = b\n",
    "        \n",
    "    return tData, tBeta\n",
    "\n",
    "\n",
    "tData, tBeta = GrandTour(data, nSteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dom\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetData = np.zeros((len(tData[0][0]), 3))\n",
    "for counter, i in enumerate(classification):\n",
    "    targetData[counter][int(i-1)] = 1\n",
    "targetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002569849433712079\n",
      "!!!!!!!!!  0  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.0776 - acc: 0.4326\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 43us/step - loss: 0.9909 - acc: 0.3764\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.9260 - acc: 0.5449\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.9173 - acc: 0.6685\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.9070 - acc: 0.6854\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8935 - acc: 0.6854\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8822 - acc: 0.6573\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8765 - acc: 0.6348\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8713 - acc: 0.5730\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 54us/step - loss: 0.8639 - acc: 0.6180\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8601 - acc: 0.6517\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8575 - acc: 0.6685\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8509 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8475 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8431 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8443 - acc: 0.6573\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 958us/step - loss: 0.8365 - acc: 0.6573\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8326 - acc: 0.6517\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8325 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 56us/step - loss: 0.8278 - acc: 0.6517\n",
      "9.38842251285837\n",
      "!!!!!!!!!  10  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8252 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8222 - acc: 0.6180\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8235 - acc: 0.6573\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8186 - acc: 0.6685\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8175 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8147 - acc: 0.6348\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 885us/step - loss: 0.8157 - acc: 0.6404\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.8111 - acc: 0.6517\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 829us/step - loss: 0.8118 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8087 - acc: 0.6180\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8069 - acc: 0.6236\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8076 - acc: 0.6124\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8049 - acc: 0.6067\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 43us/step - loss: 0.8037 - acc: 0.6067\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8067 - acc: 0.6011\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8025 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8019 - acc: 0.6067\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8008 - acc: 0.6180\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8008 - acc: 0.6124\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 42us/step - loss: 0.8008 - acc: 0.6180\n",
      "18.887810956522117\n",
      "!!!!!!!!!  20  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8008 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.7984 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8000 - acc: 0.6404\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7984 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8012 - acc: 0.6236\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7979 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8013 - acc: 0.6124\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.7999 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8031 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8020 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8014 - acc: 0.6067\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8024 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 807us/step - loss: 0.8041 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.8037 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 981us/step - loss: 0.8066 - acc: 0.6124\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8025 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8068 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.8081 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 992us/step - loss: 0.8067 - acc: 0.6236\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 51us/step - loss: 0.8077 - acc: 0.6236\n",
      "28.084575287434973\n",
      "!!!!!!!!!  30  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8122 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8081 - acc: 0.6124\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8130 - acc: 0.6124\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 38us/step - loss: 0.8100 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8159 - acc: 0.6236\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8148 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8194 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8157 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8234 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.8211 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8277 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8249 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8351 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8309 - acc: 0.6348\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8373 - acc: 0.6236\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.8363 - acc: 0.6180\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8488 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8402 - acc: 0.6180\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 991us/step - loss: 0.8485 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8441 - acc: 0.6292\n",
      "37.97648151983958\n",
      "!!!!!!!!!  40  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8502 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8476 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8566 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8505 - acc: 0.6292\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 840us/step - loss: 0.8563 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8527 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 868us/step - loss: 0.8583 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.8538 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8602 - acc: 0.6067\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8554 - acc: 0.5955\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 852us/step - loss: 0.8571 - acc: 0.6124\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8509 - acc: 0.6236\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8560 - acc: 0.6180\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 52us/step - loss: 0.8490 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8537 - acc: 0.6124\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8490 - acc: 0.6124\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8493 - acc: 0.6236\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8460 - acc: 0.6348\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8452 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8364 - acc: 0.6404\n",
      "47.14616305835057\n",
      "!!!!!!!!!  50  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8406 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8333 - acc: 0.6461\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8338 - acc: 0.6461\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.8286 - acc: 0.6404\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8280 - acc: 0.6461\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8209 - acc: 0.6404\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8235 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8138 - acc: 0.6348\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8138 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.8078 - acc: 0.6348\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8069 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.8032 - acc: 0.6404\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7983 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7915 - acc: 0.6292\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7941 - acc: 0.6236\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.7832 - acc: 0.6404\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 852us/step - loss: 0.7830 - acc: 0.6461\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7763 - acc: 0.6461\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 908us/step - loss: 0.7722 - acc: 0.6461\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7659 - acc: 0.6517\n",
      "56.898804383659126\n",
      "!!!!!!!!!  60  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7636 - acc: 0.6685\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7559 - acc: 0.6742\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 925us/step - loss: 0.7506 - acc: 0.6629\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.7415 - acc: 0.6629\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7370 - acc: 0.6573\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7281 - acc: 0.6517\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7225 - acc: 0.6573\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.7138 - acc: 0.6629\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7118 - acc: 0.6517\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7014 - acc: 0.6573\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6990 - acc: 0.6629\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6945 - acc: 0.6685\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6909 - acc: 0.6573\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6849 - acc: 0.6798\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6792 - acc: 0.6798\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6723 - acc: 0.6798\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6700 - acc: 0.6685\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 46us/step - loss: 0.6609 - acc: 0.6966\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6605 - acc: 0.6966\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6563 - acc: 0.6854\n",
      "66.94779635502209\n",
      "!!!!!!!!!  70  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6489 - acc: 0.7135\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6441 - acc: 0.7247\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6415 - acc: 0.7360\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.6333 - acc: 0.7472\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 986us/step - loss: 0.6300 - acc: 0.7528\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6217 - acc: 0.7584\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6218 - acc: 0.7528\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6115 - acc: 0.7640\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6135 - acc: 0.7528\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 36us/step - loss: 0.6049 - acc: 0.7697\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 818us/step - loss: 0.6019 - acc: 0.7584\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.5963 - acc: 0.7528\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 941us/step - loss: 0.5926 - acc: 0.7584\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.5847 - acc: 0.7584\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5827 - acc: 0.7472\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5733 - acc: 0.7528\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5732 - acc: 0.7697\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5629 - acc: 0.7697\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5631 - acc: 0.7640\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5535 - acc: 0.7640\n",
      "76.22667552578514\n",
      "!!!!!!!!!  80  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5518 - acc: 0.7865\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.5440 - acc: 0.7697\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5462 - acc: 0.7809\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5339 - acc: 0.7865\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5375 - acc: 0.7809\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5239 - acc: 0.8090\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 852us/step - loss: 0.5281 - acc: 0.8034\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.5176 - acc: 0.7978\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5218 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5096 - acc: 0.8202\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5173 - acc: 0.8034\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5055 - acc: 0.8202\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5095 - acc: 0.8146\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.5004 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5046 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4970 - acc: 0.8258\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 880us/step - loss: 0.5001 - acc: 0.8258\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4876 - acc: 0.8258\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 868us/step - loss: 0.4952 - acc: 0.8146\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4831 - acc: 0.8315\n",
      "85.99673253144192\n",
      "!!!!!!!!!  90  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4889 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4753 - acc: 0.8258\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 818us/step - loss: 0.4841 - acc: 0.8202\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4706 - acc: 0.8258\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4767 - acc: 0.8146\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 43us/step - loss: 0.4614 - acc: 0.8202\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4701 - acc: 0.8202\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4565 - acc: 0.8202\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4665 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4494 - acc: 0.8202\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4596 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4445 - acc: 0.8090\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4531 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4372 - acc: 0.8034\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 947us/step - loss: 0.4439 - acc: 0.8034\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4279 - acc: 0.8034\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 902us/step - loss: 0.4368 - acc: 0.8034\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4214 - acc: 0.8034\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4275 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4145 - acc: 0.8090\n",
      "95.448489598072\n",
      "!!!!!!!!!  100  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 846us/step - loss: 0.4220 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.4088 - acc: 0.8202\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4155 - acc: 0.8146\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4033 - acc: 0.8258\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4116 - acc: 0.8146\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.3999 - acc: 0.8427\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4065 - acc: 0.8258\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.3983 - acc: 0.8483\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4059 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 41us/step - loss: 0.3958 - acc: 0.8539\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4047 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.3960 - acc: 0.8427\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4044 - acc: 0.8539\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.3958 - acc: 0.8539\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4029 - acc: 0.8483\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.3974 - acc: 0.8483\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4016 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.3947 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.3999 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.3940 - acc: 0.8427\n",
      "105.20727566056826\n",
      "!!!!!!!!!  110  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.3990 - acc: 0.8371\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.3918 - acc: 0.8427\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 981us/step - loss: 0.3985 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.3962 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.3979 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.3938 - acc: 0.8371\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4008 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.3950 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 840us/step - loss: 0.4004 - acc: 0.8258\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.3957 - acc: 0.8371\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 864us/step - loss: 0.4027 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.3979 - acc: 0.8427\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4070 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4020 - acc: 0.8371\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 919us/step - loss: 0.4110 - acc: 0.8371\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4078 - acc: 0.8371\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4182 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4157 - acc: 0.8371\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4293 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.4242 - acc: 0.8315\n",
      "115.25654113655378\n",
      "!!!!!!!!!  120  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4424 - acc: 0.8202\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4362 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4544 - acc: 0.8258\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4493 - acc: 0.8258\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4741 - acc: 0.8090\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4677 - acc: 0.8034\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4934 - acc: 0.7978\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 56us/step - loss: 0.4887 - acc: 0.8034\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5211 - acc: 0.7753\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.5173 - acc: 0.7921\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 908us/step - loss: 0.5582 - acc: 0.7584\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5527 - acc: 0.7809\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 969us/step - loss: 0.6064 - acc: 0.7584\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 47us/step - loss: 0.6006 - acc: 0.7584\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6647 - acc: 0.7303\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.6589 - acc: 0.7191\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 902us/step - loss: 0.7383 - acc: 0.6798\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.7330 - acc: 0.7022\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8266 - acc: 0.6461\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 56us/step - loss: 0.8215 - acc: 0.6404\n",
      "123.97987078912274\n",
      "!!!!!!!!!  130  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.9343 - acc: 0.5618\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.9189 - acc: 0.5899\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.0335 - acc: 0.5225\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 1.0213 - acc: 0.5393\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.1278 - acc: 0.4831\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 1.1012 - acc: 0.4944\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.1897 - acc: 0.4438\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 1.1516 - acc: 0.4382\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.2066 - acc: 0.4157\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 1.1633 - acc: 0.4326\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.1871 - acc: 0.3876\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 1.1437 - acc: 0.4045\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.1529 - acc: 0.3876\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 1.1065 - acc: 0.4494\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.1006 - acc: 0.4326\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 1.0696 - acc: 0.4494\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 935us/step - loss: 1.0669 - acc: 0.4382\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 1.0384 - acc: 0.4775\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 891us/step - loss: 1.0329 - acc: 0.4944\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 1.0173 - acc: 0.5169\n",
      "133.5408386162269\n",
      "!!!!!!!!!  140  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1.0081 - acc: 0.5393\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 56us/step - loss: 0.9935 - acc: 0.5506\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.9836 - acc: 0.5393\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.9704 - acc: 0.5337\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.9615 - acc: 0.5393\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.9494 - acc: 0.5449\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.9384 - acc: 0.5618\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.9295 - acc: 0.5562\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 817us/step - loss: 0.9198 - acc: 0.5393\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.9052 - acc: 0.5449\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 812us/step - loss: 0.8939 - acc: 0.5506\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8817 - acc: 0.5674\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8698 - acc: 0.5674\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8591 - acc: 0.5787\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 864us/step - loss: 0.8461 - acc: 0.5787\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8351 - acc: 0.5787\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.8220 - acc: 0.5955\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.8136 - acc: 0.5955\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 801us/step - loss: 0.7945 - acc: 0.6292\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.7863 - acc: 0.6236\n",
      "143.35886249792134\n",
      "!!!!!!!!!  150  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7696 - acc: 0.6348\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.7577 - acc: 0.6348\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.7415 - acc: 0.6517\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.7320 - acc: 0.6573\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 975us/step - loss: 0.7130 - acc: 0.6742\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.7043 - acc: 0.6685\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6832 - acc: 0.6966\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6763 - acc: 0.7135\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6543 - acc: 0.7247\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.6428 - acc: 0.7416\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6259 - acc: 0.7472\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.6166 - acc: 0.7472\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5998 - acc: 0.7472\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5930 - acc: 0.7640\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5760 - acc: 0.7640\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.5675 - acc: 0.7528\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5533 - acc: 0.7528\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.5424 - acc: 0.7753\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5299 - acc: 0.7921\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.5231 - acc: 0.7921\n",
      "152.4889650001603\n",
      "!!!!!!!!!  160  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5108 - acc: 0.8034\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.5026 - acc: 0.8034\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4913 - acc: 0.8034\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4860 - acc: 0.8090\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4761 - acc: 0.8258\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.4714 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 857us/step - loss: 0.4640 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.4555 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4501 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4436 - acc: 0.8483\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4381 - acc: 0.8483\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4341 - acc: 0.8539\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4302 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4241 - acc: 0.8483\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4221 - acc: 0.8427\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 44us/step - loss: 0.4171 - acc: 0.8539\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4162 - acc: 0.8596\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4114 - acc: 0.8596\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4131 - acc: 0.8596\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 34us/step - loss: 0.4076 - acc: 0.8596\n",
      "162.1933732382654\n",
      "!!!!!!!!!  170  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4118 - acc: 0.8483\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 51us/step - loss: 0.4059 - acc: 0.8539\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4123 - acc: 0.8483\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4064 - acc: 0.8483\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4135 - acc: 0.8483\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4091 - acc: 0.8483\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4202 - acc: 0.8371\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4137 - acc: 0.8483\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4283 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4201 - acc: 0.8427\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4398 - acc: 0.8371\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4331 - acc: 0.8371\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 857us/step - loss: 0.4543 - acc: 0.8315\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.4489 - acc: 0.8315\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 924us/step - loss: 0.4735 - acc: 0.8146\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 50us/step - loss: 0.4657 - acc: 0.8202\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.4928 - acc: 0.7921\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 39us/step - loss: 0.4849 - acc: 0.8146\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 796us/step - loss: 0.5116 - acc: 0.7865\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.5053 - acc: 0.7978\n",
      "171.46359507604143\n",
      "!!!!!!!!!  180  !!!!!!!!\n",
      "Epoch 1/2\n",
      "178/178 [==============================] - 0s 980us/step - loss: 0.5304 - acc: 0.7697\n",
      "Epoch 2/2\n",
      "178/178 [==============================] - 0s 45us/step - loss: 0.5247 - acc: 0.7865\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(init_op)\n",
    "    \n",
    "for i in range(999):\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(time.clock() - start)\n",
    "        print(\"!!!!!!!!!  \" + str(i) + \"  !!!!!!!!\")\n",
    "        \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    xData = tData[i][0]\n",
    "    yData = tData[i][1]\n",
    "    trainingData = np.vstack((xData, yData)).T\n",
    "    # NN model code\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    nnet = model.fit(trainingData, targetData, epochs=2)\n",
    "    accuracy.append(np.mean(nnet.history[\"acc\"]))\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0915492961943989,\n",
       " 0.4225352129466097,\n",
       " 0.3591549302070913,\n",
       " 0.5845070426732721,\n",
       " 0.3873239424027188,\n",
       " 0.647887322264658,\n",
       " 0.3556338032366524,\n",
       " 0.4894366201380609,\n",
       " 0.5000000014691286,\n",
       " 0.6056338049156565]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321 0.9084507038056011\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21f51603828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = list(range(0, len(accuracy)))\n",
    "\n",
    "new = plt.figure()\n",
    "plt.plot(x, accuracy, \"-\", marker=\"None\")\n",
    "\n",
    "max_accuracy = max(accuracy)\n",
    "acc = max_accuracy\n",
    "max_accuracy = [i for i, j in enumerate(accuracy) if j == max_accuracy]\n",
    "max_accuracy = max_accuracy[0]\n",
    "print(max_accuracy, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 1.1139 - acc: 0.3894 - val_loss: 1.1106 - val_acc: 0.3448\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.1048 - acc: 0.3628 - val_loss: 1.1020 - val_acc: 0.3448\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0962 - acc: 0.3628 - val_loss: 1.0947 - val_acc: 0.3448\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0903 - acc: 0.3628 - val_loss: 1.0901 - val_acc: 0.3448\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0863 - acc: 0.3628 - val_loss: 1.0866 - val_acc: 0.3448\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0829 - acc: 0.3628 - val_loss: 1.0832 - val_acc: 0.3448\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0800 - acc: 0.3628 - val_loss: 1.0803 - val_acc: 0.3448\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0776 - acc: 0.3628 - val_loss: 1.0771 - val_acc: 0.3448\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 0s 106us/step - loss: 1.0745 - acc: 0.3628 - val_loss: 1.0743 - val_acc: 0.3448\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0716 - acc: 0.3628 - val_loss: 1.0714 - val_acc: 0.3448\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0688 - acc: 0.3628 - val_loss: 1.0686 - val_acc: 0.3448\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0668 - acc: 0.3628 - val_loss: 1.0658 - val_acc: 0.3448\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0639 - acc: 0.3894 - val_loss: 1.0631 - val_acc: 0.3448\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0614 - acc: 0.3982 - val_loss: 1.0600 - val_acc: 0.3448\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0587 - acc: 0.3982 - val_loss: 1.0566 - val_acc: 0.3448\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0562 - acc: 0.4071 - val_loss: 1.0530 - val_acc: 0.3448\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0541 - acc: 0.4071 - val_loss: 1.0492 - val_acc: 0.3448\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0515 - acc: 0.4159 - val_loss: 1.0457 - val_acc: 0.3793\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0486 - acc: 0.4159 - val_loss: 1.0417 - val_acc: 0.4138\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0462 - acc: 0.4159 - val_loss: 1.0377 - val_acc: 0.4138\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0431 - acc: 0.3894 - val_loss: 1.0340 - val_acc: 0.4138\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0401 - acc: 0.3982 - val_loss: 1.0296 - val_acc: 0.4138\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0370 - acc: 0.3982 - val_loss: 1.0244 - val_acc: 0.4138\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0335 - acc: 0.4159 - val_loss: 1.0188 - val_acc: 0.4138\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0302 - acc: 0.4159 - val_loss: 1.0135 - val_acc: 0.4138\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0261 - acc: 0.4248 - val_loss: 1.0079 - val_acc: 0.4138\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0224 - acc: 0.4336 - val_loss: 1.0015 - val_acc: 0.4483\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0181 - acc: 0.4336 - val_loss: 0.9957 - val_acc: 0.4138\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0145 - acc: 0.4425 - val_loss: 0.9894 - val_acc: 0.4138\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0102 - acc: 0.4425 - val_loss: 0.9834 - val_acc: 0.4138\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0071 - acc: 0.4602 - val_loss: 0.9780 - val_acc: 0.4138\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0026 - acc: 0.4602 - val_loss: 0.9723 - val_acc: 0.4138\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9986 - acc: 0.4602 - val_loss: 0.9662 - val_acc: 0.4828\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9945 - acc: 0.4425 - val_loss: 0.9604 - val_acc: 0.4828\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9906 - acc: 0.4602 - val_loss: 0.9536 - val_acc: 0.4828\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9863 - acc: 0.4602 - val_loss: 0.9481 - val_acc: 0.4828\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9827 - acc: 0.4602 - val_loss: 0.9423 - val_acc: 0.4828\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9792 - acc: 0.4602 - val_loss: 0.9368 - val_acc: 0.4828\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 0s 106us/step - loss: 0.9756 - acc: 0.4602 - val_loss: 0.9317 - val_acc: 0.4828\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9727 - acc: 0.4690 - val_loss: 0.9265 - val_acc: 0.4828\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9695 - acc: 0.4690 - val_loss: 0.9217 - val_acc: 0.4828\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9659 - acc: 0.4602 - val_loss: 0.9180 - val_acc: 0.4828\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9628 - acc: 0.4779 - val_loss: 0.9149 - val_acc: 0.4828\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9601 - acc: 0.4867 - val_loss: 0.9112 - val_acc: 0.4828\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9571 - acc: 0.4779 - val_loss: 0.9078 - val_acc: 0.5172\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9543 - acc: 0.4867 - val_loss: 0.9049 - val_acc: 0.5172\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9522 - acc: 0.5133 - val_loss: 0.9015 - val_acc: 0.5517\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9492 - acc: 0.5133 - val_loss: 0.8988 - val_acc: 0.5517\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9473 - acc: 0.5133 - val_loss: 0.8957 - val_acc: 0.5517\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9443 - acc: 0.5221 - val_loss: 0.8940 - val_acc: 0.5517\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9419 - acc: 0.5221 - val_loss: 0.8923 - val_acc: 0.5517\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9398 - acc: 0.5221 - val_loss: 0.8902 - val_acc: 0.5517\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9374 - acc: 0.5133 - val_loss: 0.8886 - val_acc: 0.5517\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9350 - acc: 0.5221 - val_loss: 0.8870 - val_acc: 0.5862\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9333 - acc: 0.5310 - val_loss: 0.8857 - val_acc: 0.5862\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9316 - acc: 0.5398 - val_loss: 0.8837 - val_acc: 0.5862\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9294 - acc: 0.5398 - val_loss: 0.8821 - val_acc: 0.5862\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9276 - acc: 0.5487 - val_loss: 0.8807 - val_acc: 0.5862\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9259 - acc: 0.5487 - val_loss: 0.8798 - val_acc: 0.5862\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9249 - acc: 0.5487 - val_loss: 0.8793 - val_acc: 0.5862\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 0s 106us/step - loss: 0.9226 - acc: 0.5398 - val_loss: 0.8780 - val_acc: 0.5862\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9209 - acc: 0.5487 - val_loss: 0.8765 - val_acc: 0.5862\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9198 - acc: 0.5487 - val_loss: 0.8758 - val_acc: 0.5862\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9184 - acc: 0.5575 - val_loss: 0.8739 - val_acc: 0.5862\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9166 - acc: 0.5664 - val_loss: 0.8726 - val_acc: 0.6207\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9152 - acc: 0.5752 - val_loss: 0.8716 - val_acc: 0.6207\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9141 - acc: 0.5664 - val_loss: 0.8706 - val_acc: 0.6552\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9129 - acc: 0.5664 - val_loss: 0.8700 - val_acc: 0.6552\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9119 - acc: 0.5929 - val_loss: 0.8700 - val_acc: 0.6897\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9107 - acc: 0.6106 - val_loss: 0.8693 - val_acc: 0.7241\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9098 - acc: 0.6637 - val_loss: 0.8688 - val_acc: 0.7241\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9085 - acc: 0.7345 - val_loss: 0.8683 - val_acc: 0.7586\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9075 - acc: 0.7434 - val_loss: 0.8680 - val_acc: 0.7586\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9064 - acc: 0.7345 - val_loss: 0.8675 - val_acc: 0.7586\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9050 - acc: 0.7434 - val_loss: 0.8668 - val_acc: 0.7586\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9040 - acc: 0.7611 - val_loss: 0.8659 - val_acc: 0.7586\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9030 - acc: 0.7522 - val_loss: 0.8654 - val_acc: 0.7586\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9021 - acc: 0.7522 - val_loss: 0.8647 - val_acc: 0.7586\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9012 - acc: 0.7522 - val_loss: 0.8632 - val_acc: 0.7931\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8996 - acc: 0.7699 - val_loss: 0.8623 - val_acc: 0.7931\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.8985 - acc: 0.7699 - val_loss: 0.8619 - val_acc: 0.7586\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8969 - acc: 0.7611 - val_loss: 0.8620 - val_acc: 0.7586\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8959 - acc: 0.7080 - val_loss: 0.8612 - val_acc: 0.7586\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8951 - acc: 0.6903 - val_loss: 0.8606 - val_acc: 0.6897\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8940 - acc: 0.6903 - val_loss: 0.8596 - val_acc: 0.7241\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8931 - acc: 0.6903 - val_loss: 0.8588 - val_acc: 0.7241\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8916 - acc: 0.6903 - val_loss: 0.8581 - val_acc: 0.7586\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8901 - acc: 0.6903 - val_loss: 0.8569 - val_acc: 0.7586\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8889 - acc: 0.7168 - val_loss: 0.8561 - val_acc: 0.7586\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8875 - acc: 0.7699 - val_loss: 0.8550 - val_acc: 0.7931\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8866 - acc: 0.7699 - val_loss: 0.8540 - val_acc: 0.7931\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.8848 - acc: 0.7611 - val_loss: 0.8538 - val_acc: 0.7931\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8836 - acc: 0.7611 - val_loss: 0.8532 - val_acc: 0.7931\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8823 - acc: 0.7788 - val_loss: 0.8532 - val_acc: 0.7931\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8804 - acc: 0.7788 - val_loss: 0.8529 - val_acc: 0.7931\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8796 - acc: 0.7788 - val_loss: 0.8527 - val_acc: 0.7586\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8778 - acc: 0.7788 - val_loss: 0.8514 - val_acc: 0.7586\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8764 - acc: 0.7788 - val_loss: 0.8499 - val_acc: 0.7931\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8743 - acc: 0.7699 - val_loss: 0.8483 - val_acc: 0.7931\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.8735 - acc: 0.7611 - val_loss: 0.8473 - val_acc: 0.8276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3893805317646634,\n",
       " 0.36283185919829175,\n",
       " 0.3628318602532412,\n",
       " 0.3628318597257665,\n",
       " 0.3628318602532412,\n",
       " 0.362831858670817,\n",
       " 0.3628318602532412,\n",
       " 0.3628318602532412,\n",
       " 0.36283185906642307,\n",
       " 0.3628318597257665,\n",
       " 0.3628318597257665,\n",
       " 0.36283185853894834,\n",
       " 0.3893805328196129,\n",
       " 0.39823008915491864,\n",
       " 0.3982300903417368,\n",
       " 0.40707964733638596,\n",
       " 0.407079650237497,\n",
       " 0.4159292048585098,\n",
       " 0.4159292048585098,\n",
       " 0.41592920723214616,\n",
       " 0.38938053519324917,\n",
       " 0.3982300887593126,\n",
       " 0.3982300887593126,\n",
       " 0.4159292048585098,\n",
       " 0.4159292043310351,\n",
       " 0.42477876290810845,\n",
       " 0.4336283187159395,\n",
       " 0.4336283222763939,\n",
       " 0.44247787742488154,\n",
       " 0.44247787742488154,\n",
       " 0.46017699194165457,\n",
       " 0.4601769924691293,\n",
       " 0.4601769924691293,\n",
       " 0.44247788032599256,\n",
       " 0.46017699141417984,\n",
       " 0.46017699128231115,\n",
       " 0.46017699194165457,\n",
       " 0.46017699194165457,\n",
       " 0.4601769953702403,\n",
       " 0.46902654893630374,\n",
       " 0.4690265528923642,\n",
       " 0.46017699194165457,\n",
       " 0.47787610645842765,\n",
       " 0.48672566450802623,\n",
       " 0.47787610645842765,\n",
       " 0.48672566450802623,\n",
       " 0.5132743383930848,\n",
       " 0.513274339975509,\n",
       " 0.513274337074398,\n",
       " 0.5221238969701582,\n",
       " 0.5221238980251076,\n",
       " 0.5221238945965219,\n",
       " 0.5132743376018727,\n",
       " 0.5221238980251076,\n",
       " 0.5309734539648073,\n",
       " 0.5398230125418807,\n",
       " 0.5398230125418807,\n",
       " 0.5486725700640045,\n",
       " 0.5486725705914792,\n",
       " 0.5486725666354187,\n",
       " 0.5398230125418807,\n",
       " 0.5486725676903682,\n",
       " 0.5486725695365298,\n",
       " 0.5575221260037042,\n",
       " 0.5663716845807776,\n",
       " 0.575221243157851,\n",
       " 0.5663716822071413,\n",
       " 0.5663716822071413,\n",
       " 0.592920357674624,\n",
       " 0.6106194721913971,\n",
       " 0.6637168167966657,\n",
       " 0.7345132780286063,\n",
       " 0.743362833968306,\n",
       " 0.7345132769736569,\n",
       " 0.743362833968306,\n",
       " 0.7610619490125538,\n",
       " 0.7522123909629552,\n",
       " 0.7522123909629552,\n",
       " 0.7522123925453794,\n",
       " 0.7699115054797282,\n",
       " 0.7699115065346777,\n",
       " 0.7610619490125538,\n",
       " 0.7079646044072851,\n",
       " 0.6902654893630373,\n",
       " 0.6902654893630373,\n",
       " 0.6902654888355626,\n",
       " 0.6902654893630373,\n",
       " 0.6902654883080879,\n",
       " 0.716814161929409,\n",
       " 0.7699115054797282,\n",
       " 0.7699115065346777,\n",
       " 0.7610619474301296,\n",
       " 0.7610619495400285,\n",
       " 0.7787610619469026,\n",
       " 0.7787610635293268,\n",
       " 0.7787610645842763,\n",
       " 0.7787610635293268,\n",
       " 0.7787610630018521,\n",
       " 0.7699115054797282,\n",
       " 0.7610619495400285]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN model code\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "abcd = model.fit(trainingData, targetData, epochs=100, validation_split=0.2)\n",
    "\n",
    "abcd.history[\"acc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = plt.figure()\n",
    "plt.plot(x, accuracy, \"-\", marker=\"None\")\n",
    "\n",
    "\n",
    "\n",
    "max_accuracy = max(accuracy)\n",
    "acc = max_accuracy\n",
    "max_accuracy = [i for i, j in enumerate(accuracy) if j == max_accuracy]\n",
    "max_accuracy = max_accuracy[0]\n",
    "print(max_accuracy, acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
