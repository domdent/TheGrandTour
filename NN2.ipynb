{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/dom/Documents/MPhys/TheGrandTour/wine_data.txt\", sep=\"\\t\");\n",
    "data = np.array(df);\n",
    "data = np.delete(data, 0, 0)\n",
    "data = data.astype(float)\n",
    "data = np.swapaxes(data,0,1)\n",
    "\n",
    "\n",
    "classification = data[13]\n",
    "data = np.delete(data, 13, axis=0)\n",
    "# Normalizes the data        \n",
    "for i in range(0, np.shape(data)[0]):\n",
    "    data[i,:] = (data[i,:] / np.ndarray.max(data[i,:])) * 2 - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepSize = 0.01\n",
    "nSteps = 10000\n",
    "\n",
    "def getAlpha(d):\n",
    "    \"\"\"\n",
    "    NEEDS IMPLEMENTATION\n",
    "    Should produce 1xd(d-1)/2 array of position in grand tour.\n",
    "    \"\"\"\n",
    "    p = d*(d-1)/2     \n",
    "    primeList = []\n",
    "    count = 1\n",
    "    while len(primeList) < p:\n",
    "        count += 1\n",
    "        primeBool = False\n",
    "        for i in range(2, count - 1):\n",
    "            if count % i == 0:\n",
    "                primeBool = True\n",
    "        if primeBool == False:\n",
    "            irrational = (np.sqrt(count)%1)\n",
    "            primeList.append(irrational)\n",
    "            \n",
    "    primeList = np.asarray(primeList)\n",
    "    primeList = primeList.dot(stepSize)\n",
    "    \"\"\"\n",
    "    Irrational number generation using exponentials, not being used\n",
    "    p = int(d*(d-1)/2)\n",
    "    alpha = np.zeros(p) #alpha(t) parameters defining grand tour in G2,d\n",
    "    for i in range(0,p):\n",
    "        alpha[i] = (np.exp(i) % 1) * 2 * np.pi\n",
    "        \n",
    "    alpha = alpha.dot(0.001)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return primeList\n",
    "\n",
    "\n",
    "def getAngles(alpha,d):\n",
    "    \"\"\"\"\"\n",
    "    Inputs: \n",
    "    alpha = 1xd(d-1)/2 array defining position on grand tour\n",
    "    d = dimensions of data\n",
    "    Outputs a dxd array of angles required for the transformation\n",
    "    \"\"\"\n",
    "    theta = np.zeros((d,d));\n",
    "    i = 0;\n",
    "    k = 0;\n",
    "    \n",
    "    while i < d-1:\n",
    "        j = i + 1;\n",
    "        \n",
    "        while j < d:\n",
    "            theta[i][j] = alpha[k];\n",
    "            j += 1;\n",
    "            k += 1;\n",
    "    \n",
    "        i+= 1;\n",
    "        \n",
    "    return theta;\n",
    "\n",
    "\n",
    "def RotationMatrix(i, j, d, theta):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    i = first indicie of rotating plane\n",
    "    j = second indicie of rotating plane\n",
    "    d = dimensions of data\n",
    "    theta = dxd array of angle of rotation of rotating plane\n",
    "    Outputs a rotating matrix to rotate plane of ixj plane by theta_ij\n",
    "    \"\"\"\n",
    "    R = np.identity(d)\n",
    "    R[i,i] = np.cos(theta)\n",
    "    R[i,j] = -1*np.sin(theta)\n",
    "    R[j,i] = np.sin(theta)\n",
    "    R[j,j] = np.cos(theta)\n",
    "    return R\n",
    "\n",
    "\n",
    "def BetaFn(d, theta):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    d = dimensions of data\n",
    "    theta = dxd array of angle of rotation ixj plane\n",
    "    Outputs the full matrix transformation for all rotations\n",
    "    \"\"\"\n",
    "    b = RotationMatrix(1, 2, d, theta[1,2])\n",
    "    i = 1\n",
    "    j = 2\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            if i==1 and j==2:\n",
    "                continue\n",
    "            b = np.matmul(b, RotationMatrix(i, j, d, theta[i,j]))\n",
    "            \n",
    "    return b\n",
    "\n",
    "\n",
    "def GrandTour(data, nSteps):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    data = array of data points, dimensions x npoints\n",
    "    Outputs a 3D array number of points x t x dimensions, where t\n",
    "    the time step at that point in the tour\n",
    "    \"\"\"\n",
    "\n",
    "    d = np.shape(data)[0] #dimensions of data\n",
    "    nPoints = np.shape(data)[1] #number of data points\n",
    "    tData = np.zeros((nSteps, d, nPoints)) #initialise 3d matrix to store stransforemd data at each timestep\n",
    "    tBeta = np.zeros((nSteps, d, d))\n",
    "    Alpha = getAlpha(d)\n",
    "\n",
    "    \n",
    "    for t in range(0, nSteps):\n",
    "        \n",
    "        \n",
    "        alpha = Alpha.dot(t)\n",
    "        theta = getAngles(alpha, d)\n",
    "        b = BetaFn(d, theta)\n",
    "        a = np.matmul(b, data)\n",
    "        tData[t,:,:] = a\n",
    "        tBeta[t,:,:] = b\n",
    "        \n",
    "    return tData, tBeta\n",
    "\n",
    "\n",
    "tData, tBeta = GrandTour(data, nSteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetData = np.zeros((len(tData[0][0]), 3))\n",
    "for counter, i in enumerate(classification):\n",
    "    targetData[counter][int(i-1)] = 1\n",
    "targetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 177])\n",
      "torch.Size([177, 3])\n",
      "torch.Size([13, 177])\n",
      "torch.Size([177, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(data)\n",
    "y = torch.from_numpy(targetData)\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "#x.transpose_(0, 1)\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 177])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([177, 13])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.size())\n",
    "x.transpose_(0, 1)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([177, 13])\n",
      "torch.Size([177, 3])\n"
     ]
    }
   ],
   "source": [
    "#print(x[0])\n",
    "#print(x[1])\n",
    "print(x.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        # parameters\n",
    "        # TODO: parameters can be parameterized instead of declaring them here\n",
    "        self.inputSize = x.size()[1]\n",
    "        self.outputSize = y.size()[1]\n",
    "        self.hiddenSize = 20\n",
    "        \n",
    "        # weights with + 1 for bias nodes\n",
    "        self.W1 = torch.randn(self.inputSize + 1, self.hiddenSize)\n",
    "        self.W2 = torch.randn(self.hiddenSize + 1, self.outputSize) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        #print(X.size())\n",
    "        #print(self.W1.size())\n",
    "        X_w_bias = torch.cat((X, torch.ones(x.size()[0], 1)), 1)\n",
    "        self.z = torch.matmul(X_w_bias, self.W1) # 3 X 3 \".dot\" does not broadcast in PyTorch\n",
    "        self.z2 = self.sigmoid(self.z) # activation function\n",
    "        z2_w_bias = torch.cat((self.z2, torch.ones(self.z2.size()[0], 1)), 1)\n",
    "        self.z3 = torch.matmul(z2_w_bias, self.W2)\n",
    "        o = self.sigmoid(self.z3) # final activation function            \n",
    "        return o\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        # derivative of sigmoid\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o # error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sig to error\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "\n",
    "        z2_w_bias = torch.cat((self.z2, torch.ones(self.z2.size()[0], 1)), 1)\n",
    "\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(z2_w_bias)\n",
    "        \n",
    "        X_w_bias = torch.cat((X, torch.ones(x.size()[0], 1)), 1)\n",
    "        print(self.z2_delta.size(), self.o_delta.size())\n",
    "        print(torch.t(X_w_bias).size())\n",
    "        print(self.W1.size())\n",
    "        self.W1 += torch.matmul(torch.t(X_w_bias), self.z2_delta)\n",
    "        self.W2 += torch.matmul(torch.t(z2_w_bias), self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # forward + backward pass for training\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "    def saveWeights(self, model):\n",
    "        # we will use the PyTorch internal storage functions\n",
    "        torch.save(model, \"NN\")\n",
    "        # you can reload model with all the weights and so forth with:\n",
    "        # torch.load(\"NN\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        print (\"Predicted data based on trained weights: \")\n",
    "        print (\"Input (scaled): \\n\" + str(X))\n",
    "        foward_fn = self.forward(X)\n",
    "        print (\"Output: \\n\" + str(foward_fn))\n",
    "        return forward_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = Neural_Network()\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.46039021015167236\n",
      "torch.Size([177, 21]) torch.Size([177, 3])\n",
      "torch.Size([14, 177])\n",
      "torch.Size([14, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (20) must match the existing size (21) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-4c3aff1a546c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# trains the NN 1,000 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Loss: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean sum squared loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-f296043df163>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# forward + backward pass for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msaveWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-f296043df163>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, X, y, o)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2_w_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (20) must match the existing size (21) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "for i in range(1000):  # trains the NN 1,000 times\n",
    "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(x)) ** 2).detach().item()))  # mean sum squared loss\n",
    "    NN.train(x, y)\n",
    "NN.saveWeights(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "accuracy: 0.576271186440678\n"
     ]
    }
   ],
   "source": [
    "predictions = NN.forward(x)\n",
    "print(\"------\")\n",
    "#print(predictions)\n",
    "#print(type(predictions))\n",
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    #print(\"prediction: \" + str(predictions[i]))\n",
    "    #print(\"actual: \" + str(y[i]))\n",
    "    pred = predictions[i].tolist()\n",
    "    actual = y[i].tolist()\n",
    "    if pred.index(max(pred)) == actual.index(max(actual)):\n",
    "        correct += 1\n",
    "\n",
    "print(\"accuracy: \" + str(correct / len(predictions)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x = x.float()\n",
    "y = y.float()\n",
    "print(x.type())\n",
    "print(y.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7802,  0.7748,  0.9380,  ...,  0.7896,  0.7761,  0.9056],\n",
       "        [-0.3862, -0.1862, -0.3276,  ...,  0.4759, -0.1069,  0.4138],\n",
       "        [ 0.3251,  0.6533,  0.5480,  ...,  0.3994,  0.4675,  0.6966],\n",
       "        ...,\n",
       "        [ 0.2281,  0.2047,  0.0058,  ..., -0.3099, -0.2982, -0.2865],\n",
       "        [ 0.7000,  0.5850,  0.7250,  ..., -0.2200, -0.1900, -0.2000],\n",
       "        [ 0.2500,  0.4107,  0.7619,  ..., -0.0060,  0.0000, -0.3333]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add bias values to input and hidden layer!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted data based on trained weights: \n",
      "Input (scaled): \n",
      "tensor([[ 0.7802, -0.3862,  0.3251,  ...,  0.2281,  0.7000,  0.2500],\n",
      "        [ 0.7748, -0.1862,  0.6533,  ...,  0.2047,  0.5850,  0.4107],\n",
      "        [ 0.9380, -0.3276,  0.5480,  ...,  0.0058,  0.7250,  0.7619],\n",
      "        ...,\n",
      "        [ 0.7896,  0.4759,  0.3994,  ..., -0.3099, -0.2200, -0.0060],\n",
      "        [ 0.7761, -0.1069,  0.4675,  ..., -0.2982, -0.1900,  0.0000],\n",
      "        [ 0.9056,  0.4138,  0.6966,  ..., -0.2865, -0.2000, -0.3333]])\n",
      "Output: \n",
      "tensor([[7.9406e-17, 2.3666e-07, 3.7494e-11],\n",
      "        [5.1035e-16, 1.3248e-07, 4.3855e-11],\n",
      "        [8.4645e-14, 1.6225e-07, 3.9584e-08],\n",
      "        [2.6061e-17, 1.2229e-07, 3.9222e-09],\n",
      "        [9.8707e-15, 2.7804e-07, 2.2305e-09],\n",
      "        [6.8918e-15, 4.7084e-07, 1.3709e-09],\n",
      "        [9.3432e-15, 3.2216e-07, 5.8709e-08],\n",
      "        [1.7848e-16, 2.2602e-07, 4.1539e-11],\n",
      "        [6.3615e-16, 2.4281e-07, 4.1475e-10],\n",
      "        [6.3757e-16, 9.5969e-08, 2.5043e-11],\n",
      "        [1.3418e-14, 4.1473e-07, 7.5559e-09],\n",
      "        [7.6585e-15, 2.9686e-07, 1.1376e-09],\n",
      "        [2.4899e-17, 2.1178e-07, 5.9712e-13],\n",
      "        [1.3179e-15, 1.4396e-07, 9.6571e-12],\n",
      "        [5.7452e-14, 2.5784e-07, 1.0342e-07],\n",
      "        [1.0394e-14, 2.0118e-07, 2.1166e-08],\n",
      "        [8.1238e-16, 2.6521e-07, 2.0237e-09],\n",
      "        [2.5017e-14, 2.0027e-07, 5.6343e-09],\n",
      "        [1.7961e-16, 1.0138e-07, 1.6257e-09],\n",
      "        [5.0404e-18, 1.1344e-07, 1.4889e-11],\n",
      "        [1.9371e-16, 1.2843e-07, 1.1974e-08],\n",
      "        [1.5492e-17, 2.0958e-07, 6.0525e-12],\n",
      "        [1.7462e-16, 3.9401e-07, 2.6175e-10],\n",
      "        [1.6039e-17, 2.7028e-07, 4.6046e-11],\n",
      "        [3.0631e-17, 3.4587e-07, 1.1600e-09],\n",
      "        [1.6692e-15, 3.7227e-07, 1.0077e-09],\n",
      "        [2.1184e-14, 5.1860e-07, 4.1316e-08],\n",
      "        [1.7510e-17, 1.8305e-07, 1.7129e-11],\n",
      "        [3.2209e-16, 3.8660e-07, 2.2303e-10],\n",
      "        [1.0011e-15, 1.6209e-07, 1.4182e-10],\n",
      "        [5.7251e-14, 1.9331e-07, 2.4242e-08],\n",
      "        [4.0034e-17, 4.1361e-07, 2.6706e-11],\n",
      "        [5.5357e-16, 6.3927e-07, 1.4854e-09],\n",
      "        [1.1370e-15, 2.5346e-07, 5.0143e-09],\n",
      "        [4.4729e-17, 1.9952e-07, 1.2002e-10],\n",
      "        [2.4139e-16, 2.3685e-07, 1.7045e-09],\n",
      "        [2.9352e-15, 2.7802e-07, 8.4956e-09],\n",
      "        [5.0479e-17, 2.5305e-07, 4.6590e-11],\n",
      "        [1.0439e-16, 1.1456e-07, 1.3900e-09],\n",
      "        [1.5623e-17, 2.0847e-07, 3.3492e-11],\n",
      "        [2.3065e-15, 1.4999e-07, 1.0604e-07],\n",
      "        [7.7454e-17, 6.9196e-08, 2.6309e-11],\n",
      "        [9.3875e-17, 9.6335e-08, 1.4794e-07],\n",
      "        [2.6910e-17, 2.2445e-07, 6.4689e-11],\n",
      "        [3.2634e-14, 1.6287e-07, 1.2576e-05],\n",
      "        [7.2661e-17, 1.0294e-07, 2.4233e-11],\n",
      "        [4.9973e-17, 1.1787e-07, 2.2828e-11],\n",
      "        [1.4481e-15, 2.2271e-07, 1.4579e-09],\n",
      "        [8.9242e-15, 3.0616e-07, 8.1713e-09],\n",
      "        [4.2192e-16, 1.0116e-07, 4.7190e-12],\n",
      "        [7.8347e-16, 1.5943e-07, 3.1478e-11],\n",
      "        [1.4842e-16, 1.4842e-07, 3.8921e-11],\n",
      "        [3.6335e-14, 4.0428e-07, 3.5580e-08],\n",
      "        [1.7498e-15, 2.2256e-07, 1.4072e-08],\n",
      "        [6.9261e-15, 1.7947e-07, 1.2099e-08],\n",
      "        [3.4085e-16, 1.9966e-07, 1.1013e-09],\n",
      "        [3.8231e-15, 1.7228e-07, 2.0233e-09],\n",
      "        [4.0261e-15, 1.0226e-07, 1.1649e-09],\n",
      "        [3.6904e-16, 3.0853e-07, 6.6973e-05],\n",
      "        [2.9267e-17, 4.8037e-07, 2.0408e-05],\n",
      "        [1.2568e-16, 1.3834e-07, 3.2039e-02],\n",
      "        [3.4037e-17, 3.7662e-07, 6.2483e-08],\n",
      "        [3.3190e-19, 5.4980e-08, 6.7901e-13],\n",
      "        [9.2789e-19, 1.7619e-07, 1.1637e-08],\n",
      "        [3.7678e-17, 4.4216e-07, 1.9224e-10],\n",
      "        [2.6310e-18, 3.2605e-07, 5.8660e-13],\n",
      "        [2.5922e-17, 1.7611e-06, 5.1648e-09],\n",
      "        [1.1033e-15, 1.0756e-06, 5.1579e-05],\n",
      "        [7.4028e-18, 1.2624e-07, 1.9377e-09],\n",
      "        [6.5422e-15, 2.9569e-07, 2.6562e-02],\n",
      "        [9.2167e-19, 9.4035e-08, 9.2948e-12],\n",
      "        [6.2614e-17, 3.2897e-07, 9.4062e-07],\n",
      "        [1.0920e-18, 5.5668e-08, 2.1807e-11],\n",
      "        [6.3667e-17, 1.2649e-07, 1.8932e-10],\n",
      "        [2.1243e-18, 7.5210e-08, 6.2153e-07],\n",
      "        [9.7845e-18, 4.3334e-07, 4.8782e-09],\n",
      "        [4.3457e-18, 4.8852e-08, 2.4717e-05],\n",
      "        [3.1613e-17, 4.8346e-07, 2.4303e-09],\n",
      "        [3.4574e-19, 6.6339e-08, 1.9942e-10],\n",
      "        [9.1352e-19, 5.9980e-07, 2.9626e-11],\n",
      "        [1.3778e-17, 2.8806e-07, 6.4754e-11],\n",
      "        [5.2609e-17, 2.7362e-06, 1.7742e-09],\n",
      "        [6.8117e-18, 1.2406e-08, 1.2346e-02],\n",
      "        [4.6228e-17, 8.1989e-07, 6.2678e-10],\n",
      "        [4.5130e-18, 6.3978e-07, 3.0195e-10],\n",
      "        [4.6527e-18, 6.0770e-07, 5.2069e-09],\n",
      "        [1.3061e-17, 1.4061e-06, 3.0618e-09],\n",
      "        [6.6844e-17, 1.3400e-06, 7.8982e-08],\n",
      "        [4.6360e-17, 4.5702e-06, 1.0660e-09],\n",
      "        [5.6380e-18, 7.3783e-07, 4.4956e-08],\n",
      "        [2.0278e-17, 1.1129e-06, 1.2392e-06],\n",
      "        [7.7836e-18, 6.5112e-07, 1.6029e-06],\n",
      "        [4.2364e-19, 7.7835e-08, 5.6501e-11],\n",
      "        [6.1015e-19, 5.3315e-08, 1.1941e-10],\n",
      "        [2.6911e-18, 9.2776e-08, 2.4438e-11],\n",
      "        [2.0435e-14, 1.2616e-07, 7.1313e-03],\n",
      "        [1.1879e-18, 2.0422e-07, 9.0230e-12],\n",
      "        [9.6035e-19, 9.7982e-08, 2.5019e-13],\n",
      "        [3.0417e-19, 7.8616e-08, 8.2664e-13],\n",
      "        [2.8287e-18, 1.6660e-07, 1.0636e-10],\n",
      "        [4.5266e-17, 1.1015e-06, 4.8124e-08],\n",
      "        [4.0257e-18, 1.8936e-07, 1.9085e-08],\n",
      "        [4.8738e-18, 5.1838e-07, 1.3249e-08],\n",
      "        [2.1593e-17, 1.4656e-06, 9.0218e-10],\n",
      "        [7.4560e-19, 8.8662e-07, 3.4570e-08],\n",
      "        [2.0683e-17, 1.5956e-06, 3.7543e-09],\n",
      "        [2.1861e-17, 7.5489e-07, 9.8447e-07],\n",
      "        [4.5922e-18, 1.4220e-06, 1.7015e-09],\n",
      "        [6.3200e-18, 3.2109e-07, 2.9361e-12],\n",
      "        [5.1212e-18, 8.3141e-08, 3.1864e-11],\n",
      "        [8.1753e-19, 8.4106e-08, 3.1257e-09],\n",
      "        [1.5635e-18, 1.0749e-07, 4.1649e-07],\n",
      "        [1.2828e-17, 1.7535e-06, 3.7172e-09],\n",
      "        [4.4277e-18, 1.5058e-06, 2.8121e-09],\n",
      "        [1.0144e-18, 1.2221e-06, 5.8645e-12],\n",
      "        [1.1822e-17, 1.5841e-06, 2.6937e-09],\n",
      "        [9.8577e-19, 3.4777e-07, 2.3723e-09],\n",
      "        [1.5324e-17, 1.0423e-08, 1.7417e-02],\n",
      "        [2.9944e-18, 1.5189e-07, 3.1628e-09],\n",
      "        [3.6420e-18, 1.9604e-07, 1.6371e-10],\n",
      "        [4.8599e-19, 2.8132e-07, 8.6008e-12],\n",
      "        [4.4174e-19, 2.9976e-08, 5.0883e-08],\n",
      "        [1.2058e-17, 1.0849e-07, 4.1602e-08],\n",
      "        [1.5335e-18, 7.2696e-08, 1.5942e-11],\n",
      "        [1.2681e-18, 4.3104e-07, 6.0655e-10],\n",
      "        [4.7156e-18, 9.3497e-07, 1.2069e-09],\n",
      "        [6.8110e-18, 8.6197e-07, 5.8111e-08],\n",
      "        [3.8073e-18, 1.1281e-06, 1.1571e-09],\n",
      "        [3.9472e-17, 3.8415e-08, 2.4062e-05],\n",
      "        [6.7330e-14, 2.6964e-08, 9.7153e-01],\n",
      "        [2.1274e-14, 4.8751e-09, 9.9976e-01],\n",
      "        [4.3574e-14, 1.1739e-08, 9.9993e-01],\n",
      "        [6.5252e-14, 6.1506e-09, 9.9972e-01],\n",
      "        [3.7940e-14, 3.4609e-07, 9.6677e-01],\n",
      "        [4.3462e-14, 7.9816e-08, 9.9987e-01],\n",
      "        [6.6324e-15, 3.2598e-09, 9.9986e-01],\n",
      "        [8.3192e-16, 2.0625e-09, 9.9965e-01],\n",
      "        [5.3879e-15, 1.2318e-08, 9.9937e-01],\n",
      "        [1.7586e-14, 4.8285e-08, 9.8669e-01],\n",
      "        [1.0902e-14, 4.2179e-08, 9.9537e-01],\n",
      "        [2.9266e-13, 5.2037e-08, 9.9971e-01],\n",
      "        [2.6508e-15, 1.0172e-08, 9.9649e-01],\n",
      "        [1.5363e-15, 5.0809e-09, 9.8192e-01],\n",
      "        [1.1024e-13, 6.2383e-09, 9.9999e-01],\n",
      "        [3.0226e-14, 1.1666e-08, 9.9962e-01],\n",
      "        [1.6425e-14, 2.9616e-09, 9.9999e-01],\n",
      "        [3.3061e-14, 4.7025e-09, 9.9999e-01],\n",
      "        [1.0434e-13, 1.3576e-08, 9.9999e-01],\n",
      "        [4.2126e-14, 4.0968e-09, 1.0000e+00],\n",
      "        [4.9023e-14, 3.5763e-09, 9.9999e-01],\n",
      "        [1.1104e-13, 6.9867e-09, 1.0000e+00],\n",
      "        [2.2656e-13, 1.7620e-08, 9.9981e-01],\n",
      "        [1.8343e-13, 3.9400e-08, 9.9999e-01],\n",
      "        [2.2311e-13, 1.5598e-07, 9.9997e-01],\n",
      "        [3.5887e-14, 5.8063e-09, 9.9999e-01],\n",
      "        [4.0424e-14, 5.4969e-09, 9.9999e-01],\n",
      "        [1.6673e-13, 7.5842e-08, 9.9999e-01],\n",
      "        [3.7562e-12, 2.7130e-07, 9.9998e-01],\n",
      "        [1.7090e-12, 1.9128e-07, 9.9999e-01],\n",
      "        [1.7266e-14, 6.9981e-09, 9.9998e-01],\n",
      "        [1.5414e-14, 8.2320e-09, 9.9962e-01],\n",
      "        [2.8107e-15, 2.1507e-08, 9.9745e-01],\n",
      "        [2.0435e-14, 6.0779e-09, 9.9990e-01],\n",
      "        [1.5336e-13, 2.3319e-08, 1.0000e+00],\n",
      "        [9.1680e-15, 4.6966e-09, 9.9995e-01],\n",
      "        [3.1141e-14, 4.0097e-09, 1.0000e+00],\n",
      "        [8.2202e-14, 1.0218e-08, 1.0000e+00],\n",
      "        [1.5553e-13, 1.9825e-08, 9.9999e-01],\n",
      "        [6.8547e-14, 3.8238e-09, 9.9999e-01],\n",
      "        [1.8144e-14, 1.1173e-08, 9.9994e-01],\n",
      "        [1.2861e-13, 5.7634e-08, 1.0000e+00],\n",
      "        [2.8865e-13, 2.8483e-08, 9.9999e-01],\n",
      "        [3.6773e-14, 3.7596e-09, 9.9999e-01],\n",
      "        [4.1262e-14, 5.2505e-09, 9.9999e-01],\n",
      "        [5.8590e-14, 4.5932e-09, 1.0000e+00],\n",
      "        [2.0229e-13, 3.5942e-08, 1.0000e+00],\n",
      "        [3.0843e-14, 5.4640e-09, 9.9999e-01]])\n"
     ]
    }
   ],
   "source": [
    "NN.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/dom/Documents/MPhys/TheGrandTour/wine_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([177, 13])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([177, 14])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, torch.ones(x.size()[0], 1)), 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
