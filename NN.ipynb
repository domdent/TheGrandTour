{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dom\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sklearn\n",
    "\n",
    "\n",
    "readdata = pd.read_csv(\"C:/Users/Dom/MPhys/TheGrandTour/wine_data.txt\", sep=\"\\t\", header=None);\n",
    "data = np.array(readdata);\n",
    "data = np.delete(data, 0, 0)\n",
    "data = data.astype(float)\n",
    "data = np.swapaxes(data,0,1)\n",
    "\n",
    "\n",
    "# Need to seperate the classification dimension:\n",
    "classification = data[13]\n",
    "data = np.delete(data, 13, axis=0)\n",
    "\n",
    "\n",
    "# make list of colours for each number:\n",
    "data_colour = []\n",
    "for i in range(len(classification)):\n",
    "    if classification[i] == 1:\n",
    "        data_colour.append(\"r\")\n",
    "    elif classification[i] == 2:\n",
    "        data_colour.append(\"b\")\n",
    "    elif classification[i] == 3:\n",
    "        data_colour.append(\"g\")\n",
    "        \n",
    "# Normalizes the data        \n",
    "for i in range(0, np.shape(data)[0]):\n",
    "    data[i,:] = (data[i,:] / np.ndarray.max(data[i,:])) * 2 - 1\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "#VARIABLES\n",
    "stepSize = 0.01\n",
    "nSteps = 10000\n",
    "\n",
    "def getAlpha(d):\n",
    "    \"\"\"\n",
    "    NEEDS IMPLEMENTATION\n",
    "    Should produce 1xd(d-1)/2 array of position in grand tour.\n",
    "    \"\"\"\n",
    "    p = d*(d-1)/2     \n",
    "    primeList = []\n",
    "    count = 1\n",
    "    while len(primeList) < p:\n",
    "        count += 1\n",
    "        primeBool = False\n",
    "        for i in range(2, count - 1):\n",
    "            if count % i == 0:\n",
    "                primeBool = True\n",
    "        if primeBool == False:\n",
    "            irrational = (np.sqrt(count)%1)\n",
    "            primeList.append(irrational)\n",
    "            \n",
    "    primeList = np.asarray(primeList)\n",
    "    primeList = primeList.dot(stepSize)\n",
    "    \"\"\"\n",
    "    Irrational number generation using exponentials, not being used\n",
    "    p = int(d*(d-1)/2)\n",
    "    alpha = np.zeros(p) #alpha(t) parameters defining grand tour in G2,d\n",
    "    for i in range(0,p):\n",
    "        alpha[i] = (np.exp(i) % 1) * 2 * np.pi\n",
    "        \n",
    "    alpha = alpha.dot(0.001)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return primeList\n",
    "\n",
    "\n",
    "def getAngles(alpha,d):\n",
    "    \"\"\"\"\"\n",
    "    Inputs: \n",
    "    alpha = 1xd(d-1)/2 array defining position on grand tour\n",
    "    d = dimensions of data\n",
    "    Outputs a dxd array of angles required for the transformation\n",
    "    \"\"\"\n",
    "    theta = np.zeros((d,d));\n",
    "    i = 0;\n",
    "    k = 0;\n",
    "    \n",
    "    while i < d-1:\n",
    "        j = i + 1;\n",
    "        \n",
    "        while j < d:\n",
    "            theta[i][j] = alpha[k];\n",
    "            j += 1;\n",
    "            k += 1;\n",
    "    \n",
    "        i+= 1;\n",
    "        \n",
    "    return theta;\n",
    "\n",
    "\n",
    "def RotationMatrix(i, j, d, theta):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    i = first indicie of rotating plane\n",
    "    j = second indicie of rotating plane\n",
    "    d = dimensions of data\n",
    "    theta = dxd array of angle of rotation of rotating plane\n",
    "    Outputs a rotating matrix to rotate plane of ixj plane by theta_ij\n",
    "    \"\"\"\n",
    "    R = np.identity(d)\n",
    "    R[i,i] = np.cos(theta)\n",
    "    R[i,j] = -1*np.sin(theta)\n",
    "    R[j,i] = np.sin(theta)\n",
    "    R[j,j] = np.cos(theta)\n",
    "    return R\n",
    "\n",
    "\n",
    "def BetaFn(d, theta):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    d = dimensions of data\n",
    "    theta = dxd array of angle of rotation ixj plane\n",
    "    Outputs the full matrix transformation for all rotations\n",
    "    \"\"\"\n",
    "    b = RotationMatrix(1, 2, d, theta[1,2])\n",
    "    i = 1\n",
    "    j = 2\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            if i==1 and j==2:\n",
    "                continue\n",
    "            b = np.matmul(b, RotationMatrix(i, j, d, theta[i,j]))\n",
    "            \n",
    "    return b\n",
    "\n",
    "\n",
    "def GrandTour(data, nSteps):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    data = array of data points, dimensions x npoints\n",
    "    Outputs a 3D array number of points x t x dimensions, where t\n",
    "    the time step at that point in the tour\n",
    "    \"\"\"\n",
    "\n",
    "    d = np.shape(data)[0] #dimensions of data\n",
    "    nPoints = np.shape(data)[1] #number of data points\n",
    "    tData = np.zeros((nSteps,d,nPoints)) #initialise 3d matrix to store stransforemd data at each timestep\n",
    "    tBeta = np.zeros((nSteps,d,d))\n",
    "    Alpha = getAlpha(d)\n",
    "\n",
    "    \n",
    "    for t in range(0, nSteps):\n",
    "        \n",
    "        \n",
    "        alpha = Alpha.dot(t)\n",
    "        theta = getAngles(alpha, d)\n",
    "        b = BetaFn(d, theta)\n",
    "        a = np.matmul(b, data)\n",
    "        tData[t,:,:] = a\n",
    "        tBeta[t,:,:] = b\n",
    "        \n",
    "    return tData, tBeta\n",
    "\n",
    "\n",
    "tData, tBeta = GrandTour(data, nSteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dom\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetData = np.zeros((len(tData[0][0]), 3))\n",
    "for counter, i in enumerate(classification):\n",
    "    targetData[counter][int(i-1)] = 1\n",
    "targetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016483169844860868\n",
      "!!!!!!!!!  0  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.0805 - acc: 0.4155 - val_loss: 1.2802 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 77us/step - loss: 1.0710 - acc: 0.4155 - val_loss: 1.3020 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.0249 - acc: 0.4296 - val_loss: 1.2984 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 56us/step - loss: 0.9953 - acc: 0.4155 - val_loss: 1.3973 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.0936 - acc: 0.4014 - val_loss: 1.0918 - val_acc: 0.5556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 49us/step - loss: 1.0792 - acc: 0.4014 - val_loss: 1.1419 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 1.2496 - acc: 0.0845 - val_loss: 0.9447 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 56us/step - loss: 1.1926 - acc: 0.0845 - val_loss: 1.0166 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.1484 - acc: 0.0845 - val_loss: 1.0047 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 70us/step - loss: 1.1322 - acc: 0.0845 - val_loss: 1.0344 - val_acc: 1.0000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.0704 - acc: 0.5000 - val_loss: 1.1389 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 63us/step - loss: 1.0524 - acc: 0.5000 - val_loss: 1.1798 - val_acc: 0.0000e+00\n",
      "9.01539316553807\n",
      "!!!!!!!!!  10  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 5ms/step - loss: 1.0546 - acc: 0.4155 - val_loss: 1.3190 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 63us/step - loss: 1.0415 - acc: 0.4155 - val_loss: 1.3341 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 1.0718 - acc: 0.4155 - val_loss: 1.1744 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 63us/step - loss: 1.0556 - acc: 0.4155 - val_loss: 1.2081 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 1.1120 - acc: 0.4155 - val_loss: 1.1142 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 70us/step - loss: 1.0969 - acc: 0.4155 - val_loss: 1.1369 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 1.1377 - acc: 0.1056 - val_loss: 1.1028 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 63us/step - loss: 1.1188 - acc: 0.2958 - val_loss: 1.1280 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 1.0864 - acc: 0.3944 - val_loss: 1.0766 - val_acc: 0.7222\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 113us/step - loss: 1.0659 - acc: 0.4014 - val_loss: 1.1063 - val_acc: 0.4444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1459 - acc: 0.0845 - val_loss: 1.0072 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 57us/step - loss: 1.1198 - acc: 0.2042 - val_loss: 1.0424 - val_acc: 0.7500\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 8ms/step - loss: 1.1258 - acc: 0.0845 - val_loss: 1.0783 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 62us/step - loss: 1.1036 - acc: 0.1197 - val_loss: 1.1044 - val_acc: 0.0278\n",
      "21.825314502162684\n",
      "!!!!!!!!!  20  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 1.0416 - acc: 0.4155 - val_loss: 1.2397 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 127us/step - loss: 1.0237 - acc: 0.4577 - val_loss: 1.2736 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 0.9737 - acc: 0.6127 - val_loss: 1.3751 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 105us/step - loss: 0.9524 - acc: 0.5704 - val_loss: 1.4270 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 1.1048 - acc: 0.3239 - val_loss: 1.0824 - val_acc: 0.3611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 77us/step - loss: 1.0762 - acc: 0.5000 - val_loss: 1.1301 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 1.1484 - acc: 0.4225 - val_loss: 1.1196 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 96us/step - loss: 1.1209 - acc: 0.4296 - val_loss: 1.1506 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 1.0870 - acc: 0.5000 - val_loss: 1.1280 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 70us/step - loss: 1.0697 - acc: 0.5000 - val_loss: 1.1574 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 1.1181 - acc: 0.0986 - val_loss: 1.1602 - val_acc: 0.1111\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 92us/step - loss: 1.0927 - acc: 0.4014 - val_loss: 1.1959 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 1.2180 - acc: 0.0845 - val_loss: 1.0680 - val_acc: 0.4444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 107us/step - loss: 1.1821 - acc: 0.1197 - val_loss: 1.1072 - val_acc: 0.1111\n",
      "37.93260133958575\n",
      "!!!!!!!!!  30  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 11ms/step - loss: 1.0964 - acc: 0.5000 - val_loss: 1.1470 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 112us/step - loss: 1.0740 - acc: 0.5000 - val_loss: 1.1866 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 1.1958 - acc: 0.0986 - val_loss: 1.0508 - val_acc: 0.6111\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 126us/step - loss: 1.1563 - acc: 0.1338 - val_loss: 1.0921 - val_acc: 0.4444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 12ms/step - loss: 1.0517 - acc: 0.3944 - val_loss: 1.2033 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 112us/step - loss: 1.0225 - acc: 0.3732 - val_loss: 1.2619 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 1.0875 - acc: 0.3099 - val_loss: 1.1670 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 84us/step - loss: 1.0645 - acc: 0.4930 - val_loss: 1.1989 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 1.0807 - acc: 0.5000 - val_loss: 1.1711 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 77us/step - loss: 1.0574 - acc: 0.5000 - val_loss: 1.2124 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 1.0939 - acc: 0.3239 - val_loss: 1.1316 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 75us/step - loss: 1.0728 - acc: 0.4930 - val_loss: 1.1627 - val_acc: 0.0000e+00\n",
      "53.82614668343671\n",
      "!!!!!!!!!  40  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 13ms/step - loss: 1.1023 - acc: 0.5000 - val_loss: 1.1249 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 127us/step - loss: 1.0728 - acc: 0.4930 - val_loss: 1.1673 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 14ms/step - loss: 1.0094 - acc: 0.4930 - val_loss: 1.2922 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 119us/step - loss: 0.9944 - acc: 0.4930 - val_loss: 1.3356 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 1.0987 - acc: 0.4366 - val_loss: 1.1605 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 91us/step - loss: 1.0635 - acc: 0.5000 - val_loss: 1.2187 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 1.1635 - acc: 0.0493 - val_loss: 1.0714 - val_acc: 0.4444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 101us/step - loss: 1.1446 - acc: 0.0775 - val_loss: 1.0957 - val_acc: 0.0556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 15ms/step - loss: 1.0810 - acc: 0.4437 - val_loss: 1.1516 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 83us/step - loss: 1.0598 - acc: 0.4366 - val_loss: 1.1870 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 16ms/step - loss: 1.0539 - acc: 0.4930 - val_loss: 1.1551 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 98us/step - loss: 1.0310 - acc: 0.4930 - val_loss: 1.1969 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 1.2118 - acc: 0.1127 - val_loss: 1.0486 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 155us/step - loss: 1.1622 - acc: 0.4859 - val_loss: 1.1039 - val_acc: 0.0000e+00\n",
      "75.04381532869155\n",
      "!!!!!!!!!  50  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 1.0494 - acc: 0.5211 - val_loss: 1.1552 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 140us/step - loss: 1.0333 - acc: 0.5211 - val_loss: 1.1857 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 2s 17ms/step - loss: 1.1975 - acc: 0.0845 - val_loss: 1.0122 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 91us/step - loss: 1.1655 - acc: 0.0986 - val_loss: 1.0496 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 1.1148 - acc: 0.1831 - val_loss: 1.1360 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 85us/step - loss: 1.0902 - acc: 0.4789 - val_loss: 1.1743 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 1.1019 - acc: 0.4225 - val_loss: 1.1311 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 91us/step - loss: 1.0830 - acc: 0.4366 - val_loss: 1.1529 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 1.0969 - acc: 0.5141 - val_loss: 1.0859 - val_acc: 0.1944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 140us/step - loss: 1.0752 - acc: 0.5211 - val_loss: 1.1175 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 1.0721 - acc: 0.4859 - val_loss: 1.1865 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 119us/step - loss: 1.0577 - acc: 0.5000 - val_loss: 1.2093 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 1.1545 - acc: 0.0775 - val_loss: 1.0285 - val_acc: 0.6389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 140us/step - loss: 1.1201 - acc: 0.1127 - val_loss: 1.0783 - val_acc: 0.0278\n",
      "99.62761383142166\n",
      "!!!!!!!!!  60  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 1.0845 - acc: 0.4718 - val_loss: 1.1958 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 98us/step - loss: 1.0631 - acc: 0.5000 - val_loss: 1.2255 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 1.0973 - acc: 0.4296 - val_loss: 1.1315 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 91us/step - loss: 1.0720 - acc: 0.5704 - val_loss: 1.1640 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 1.1039 - acc: 0.4155 - val_loss: 1.1704 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 101us/step - loss: 1.0738 - acc: 0.4225 - val_loss: 1.2080 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 1.0982 - acc: 0.4085 - val_loss: 1.1768 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 98us/step - loss: 1.0825 - acc: 0.4296 - val_loss: 1.2043 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 1.0896 - acc: 0.4859 - val_loss: 1.1062 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 92us/step - loss: 1.0792 - acc: 0.5000 - val_loss: 1.1165 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 1.1134 - acc: 0.1056 - val_loss: 1.0761 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 105us/step - loss: 1.0943 - acc: 0.3169 - val_loss: 1.1086 - val_acc: 0.0000e+00\n",
      "123.17025765163694\n",
      "!!!!!!!!!  70  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 0.9886 - acc: 0.4296 - val_loss: 1.4120 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 91us/step - loss: 0.9666 - acc: 0.5634 - val_loss: 1.4523 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 1.0946 - acc: 0.3310 - val_loss: 1.0409 - val_acc: 0.8333\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 106us/step - loss: 1.0795 - acc: 0.5282 - val_loss: 1.0641 - val_acc: 0.6111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 1.0801 - acc: 0.5000 - val_loss: 1.0796 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 113us/step - loss: 1.0661 - acc: 0.5000 - val_loss: 1.0977 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 1.0742 - acc: 0.4507 - val_loss: 1.2045 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 105us/step - loss: 1.0632 - acc: 0.5352 - val_loss: 1.2256 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 1.0770 - acc: 0.4789 - val_loss: 1.2447 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 106us/step - loss: 1.0639 - acc: 0.5000 - val_loss: 1.2596 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 4s 26ms/step - loss: 1.0678 - acc: 0.4930 - val_loss: 1.0876 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 106us/step - loss: 1.0497 - acc: 0.5000 - val_loss: 1.1213 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 1.0995 - acc: 0.3239 - val_loss: 1.2049 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 116us/step - loss: 1.0820 - acc: 0.3662 - val_loss: 1.2209 - val_acc: 0.0000e+00\n",
      "154.7417116459065\n",
      "!!!!!!!!!  80  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 1.0719 - acc: 0.5211 - val_loss: 1.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 112us/step - loss: 1.0573 - acc: 0.5282 - val_loss: 1.1336 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 1.0826 - acc: 0.3944 - val_loss: 1.1060 - val_acc: 0.3056\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 119us/step - loss: 1.0741 - acc: 0.4014 - val_loss: 1.1151 - val_acc: 0.1944\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 1.1131 - acc: 0.0845 - val_loss: 1.0748 - val_acc: 0.6944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 119us/step - loss: 1.1000 - acc: 0.3099 - val_loss: 1.0877 - val_acc: 0.2778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 1.0799 - acc: 0.4859 - val_loss: 1.2825 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 112us/step - loss: 1.0701 - acc: 0.5282 - val_loss: 1.3058 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 1.1341 - acc: 0.4155 - val_loss: 1.0130 - val_acc: 0.7778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 127us/step - loss: 1.1172 - acc: 0.4507 - val_loss: 1.0293 - val_acc: 0.7778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 1.0940 - acc: 0.3380 - val_loss: 1.2856 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 120us/step - loss: 1.0752 - acc: 0.3310 - val_loss: 1.3148 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 1.0804 - acc: 0.4930 - val_loss: 1.3144 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 133us/step - loss: 1.0669 - acc: 0.5352 - val_loss: 1.3242 - val_acc: 0.0000e+00\n",
      "189.6860105660036\n",
      "!!!!!!!!!  90  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 1.0685 - acc: 0.4859 - val_loss: 1.4865 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 126us/step - loss: 1.0552 - acc: 0.5000 - val_loss: 1.5051 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 1.0621 - acc: 0.5352 - val_loss: 1.3967 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 126us/step - loss: 1.0423 - acc: 0.5915 - val_loss: 1.4235 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 1.0579 - acc: 0.6056 - val_loss: 1.2487 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 140us/step - loss: 1.0392 - acc: 0.6761 - val_loss: 1.2689 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 1.1205 - acc: 0.4155 - val_loss: 1.0869 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 147us/step - loss: 1.1044 - acc: 0.4155 - val_loss: 1.0998 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 1.0649 - acc: 0.5070 - val_loss: 1.1733 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 133us/step - loss: 1.0463 - acc: 0.5352 - val_loss: 1.1900 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 1.0479 - acc: 0.5704 - val_loss: 1.1648 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 126us/step - loss: 1.0327 - acc: 0.6620 - val_loss: 1.1848 - val_acc: 0.0000e+00\n",
      "220.75006992583667\n",
      "!!!!!!!!!  100  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 1.0677 - acc: 0.5493 - val_loss: 1.0200 - val_acc: 0.9444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 121us/step - loss: 1.0489 - acc: 0.7183 - val_loss: 1.0242 - val_acc: 0.1111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 34ms/step - loss: 1.0892 - acc: 0.3662 - val_loss: 0.9511 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 169us/step - loss: 1.0739 - acc: 0.4085 - val_loss: 0.9637 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 1.1325 - acc: 0.2465 - val_loss: 1.0411 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 161us/step - loss: 1.1134 - acc: 0.4718 - val_loss: 1.0486 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 4s 32ms/step - loss: 1.0914 - acc: 0.4437 - val_loss: 1.1686 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 170us/step - loss: 1.0743 - acc: 0.5704 - val_loss: 1.1774 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 1.0764 - acc: 0.5000 - val_loss: 1.2043 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 133us/step - loss: 1.0545 - acc: 0.5000 - val_loss: 1.2132 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 35ms/step - loss: 1.1065 - acc: 0.2958 - val_loss: 1.2367 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 140us/step - loss: 1.0890 - acc: 0.6338 - val_loss: 1.2308 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 1.0790 - acc: 0.5915 - val_loss: 1.1134 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 119us/step - loss: 1.0594 - acc: 0.6127 - val_loss: 1.1068 - val_acc: 0.0833\n",
      "260.51343396575953\n",
      "!!!!!!!!!  110  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 36ms/step - loss: 1.1011 - acc: 0.1972 - val_loss: 1.1236 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 166us/step - loss: 1.0855 - acc: 0.4859 - val_loss: 1.1241 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 38ms/step - loss: 1.0735 - acc: 0.7606 - val_loss: 1.0628 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 120us/step - loss: 1.0605 - acc: 0.8592 - val_loss: 1.0658 - val_acc: 0.9167\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 39ms/step - loss: 1.1543 - acc: 0.3521 - val_loss: 1.1460 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 119us/step - loss: 1.1370 - acc: 0.4507 - val_loss: 1.1320 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 39ms/step - loss: 1.1264 - acc: 0.1056 - val_loss: 1.2050 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 155us/step - loss: 1.1120 - acc: 0.1408 - val_loss: 1.1973 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 5s 38ms/step - loss: 1.0933 - acc: 0.3592 - val_loss: 1.0519 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 166us/step - loss: 1.0787 - acc: 0.6056 - val_loss: 1.0530 - val_acc: 0.7222\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 42ms/step - loss: 1.0697 - acc: 0.7324 - val_loss: 1.1572 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 162us/step - loss: 1.0517 - acc: 0.7676 - val_loss: 1.1639 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 42ms/step - loss: 1.0879 - acc: 0.6197 - val_loss: 1.0436 - val_acc: 0.8056\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 145us/step - loss: 1.0755 - acc: 0.7817 - val_loss: 1.0453 - val_acc: 0.6389\n",
      "305.28729326294194\n",
      "!!!!!!!!!  120  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 43ms/step - loss: 1.0526 - acc: 0.5000 - val_loss: 1.1468 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 154us/step - loss: 1.0367 - acc: 0.5000 - val_loss: 1.1599 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 40ms/step - loss: 1.0945 - acc: 0.2394 - val_loss: 1.0751 - val_acc: 0.5278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 159us/step - loss: 1.0791 - acc: 0.2606 - val_loss: 1.0878 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 42ms/step - loss: 1.0955 - acc: 0.3873 - val_loss: 1.1294 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 155us/step - loss: 1.0878 - acc: 0.4930 - val_loss: 1.1356 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 1.0932 - acc: 0.5000 - val_loss: 1.1298 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 153us/step - loss: 1.0752 - acc: 0.5000 - val_loss: 1.1491 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 43ms/step - loss: 1.0894 - acc: 0.4155 - val_loss: 1.1646 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 152us/step - loss: 1.0761 - acc: 0.5000 - val_loss: 1.1837 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 41ms/step - loss: 1.0960 - acc: 0.4085 - val_loss: 1.1574 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 253us/step - loss: 1.0821 - acc: 0.4930 - val_loss: 1.1800 - val_acc: 0.0000e+00\n",
      "346.7991091794846\n",
      "!!!!!!!!!  130  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 1.0938 - acc: 0.4085 - val_loss: 1.1829 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 140us/step - loss: 1.0811 - acc: 0.4507 - val_loss: 1.2113 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 44ms/step - loss: 1.0982 - acc: 0.3803 - val_loss: 1.1118 - val_acc: 0.1667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 141us/step - loss: 1.0824 - acc: 0.4577 - val_loss: 1.1370 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 42ms/step - loss: 1.1092 - acc: 0.2887 - val_loss: 1.0959 - val_acc: 0.3056\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 147us/step - loss: 1.0968 - acc: 0.3803 - val_loss: 1.1239 - val_acc: 0.0556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 44ms/step - loss: 1.1008 - acc: 0.2958 - val_loss: 1.1041 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 204us/step - loss: 1.0926 - acc: 0.5352 - val_loss: 1.1166 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 47ms/step - loss: 1.0999 - acc: 0.2746 - val_loss: 1.1009 - val_acc: 0.1944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 147us/step - loss: 1.0900 - acc: 0.4789 - val_loss: 1.1239 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 45ms/step - loss: 1.0894 - acc: 0.3873 - val_loss: 1.0673 - val_acc: 0.6667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 162us/step - loss: 1.0778 - acc: 0.4225 - val_loss: 1.0921 - val_acc: 0.5278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 6s 41ms/step - loss: 1.0561 - acc: 0.4789 - val_loss: 1.1265 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 183us/step - loss: 1.0422 - acc: 0.5000 - val_loss: 1.1568 - val_acc: 0.0000e+00\n",
      "396.1719581167031\n",
      "!!!!!!!!!  140  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 50ms/step - loss: 1.1152 - acc: 0.4014 - val_loss: 1.0905 - val_acc: 0.3889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 197us/step - loss: 1.1048 - acc: 0.4296 - val_loss: 1.1082 - val_acc: 0.2222\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 46ms/step - loss: 1.0813 - acc: 0.4859 - val_loss: 1.1150 - val_acc: 0.1667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 147us/step - loss: 1.0705 - acc: 0.4930 - val_loss: 1.1316 - val_acc: 0.0556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 48ms/step - loss: 1.0921 - acc: 0.3944 - val_loss: 1.1164 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 232us/step - loss: 1.0808 - acc: 0.4366 - val_loss: 1.1341 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 53ms/step - loss: 1.1378 - acc: 0.1408 - val_loss: 1.1198 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 175us/step - loss: 1.1210 - acc: 0.2465 - val_loss: 1.1417 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 54ms/step - loss: 1.1148 - acc: 0.1479 - val_loss: 1.1315 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 154us/step - loss: 1.0995 - acc: 0.3732 - val_loss: 1.1474 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 51ms/step - loss: 1.1119 - acc: 0.1197 - val_loss: 1.1363 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 154us/step - loss: 1.0983 - acc: 0.3592 - val_loss: 1.1487 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 50ms/step - loss: 1.1011 - acc: 0.4507 - val_loss: 1.1087 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 182us/step - loss: 1.0859 - acc: 0.4718 - val_loss: 1.1180 - val_acc: 0.0000e+00\n",
      "451.904730195672\n",
      "!!!!!!!!!  150  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 55ms/step - loss: 1.0767 - acc: 0.4507 - val_loss: 1.0186 - val_acc: 0.7778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 162us/step - loss: 1.0530 - acc: 0.5141 - val_loss: 1.0341 - val_acc: 0.6944\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 7s 49ms/step - loss: 1.1018 - acc: 0.4225 - val_loss: 0.9985 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 170us/step - loss: 1.0774 - acc: 0.4648 - val_loss: 1.0221 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 7s 52ms/step - loss: 1.0099 - acc: 0.5070 - val_loss: 1.1209 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 195us/step - loss: 0.9966 - acc: 0.5352 - val_loss: 1.1327 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 56ms/step - loss: 1.0837 - acc: 0.4859 - val_loss: 1.0732 - val_acc: 0.3333\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.0714 - acc: 0.5352 - val_loss: 1.0808 - val_acc: 0.2778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 57ms/step - loss: 1.1579 - acc: 0.1761 - val_loss: 1.0587 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 190us/step - loss: 1.1361 - acc: 0.2465 - val_loss: 1.0743 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 54ms/step - loss: 1.0893 - acc: 0.1479 - val_loss: 1.0832 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 189us/step - loss: 1.0768 - acc: 0.4085 - val_loss: 1.0996 - val_acc: 0.0000e+00\n",
      "503.23942168871537\n",
      "!!!!!!!!!  160  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 53ms/step - loss: 1.1552 - acc: 0.3944 - val_loss: 1.0298 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.1260 - acc: 0.4296 - val_loss: 1.0459 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 55ms/step - loss: 1.0362 - acc: 0.5775 - val_loss: 1.1719 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 167us/step - loss: 1.0184 - acc: 0.6127 - val_loss: 1.1876 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 55ms/step - loss: 1.0603 - acc: 0.1901 - val_loss: 1.1370 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.0396 - acc: 0.1901 - val_loss: 1.1529 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 61ms/step - loss: 1.1143 - acc: 0.4155 - val_loss: 1.1587 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.0906 - acc: 0.4155 - val_loss: 1.1729 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 54ms/step - loss: 1.0292 - acc: 0.5000 - val_loss: 1.1445 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.0047 - acc: 0.5000 - val_loss: 1.1619 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 8s 57ms/step - loss: 1.1604 - acc: 0.4014 - val_loss: 1.0649 - val_acc: 0.5833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 190us/step - loss: 1.1368 - acc: 0.4577 - val_loss: 1.0764 - val_acc: 0.3333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 62ms/step - loss: 1.0737 - acc: 0.5000 - val_loss: 1.0954 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 182us/step - loss: 1.0536 - acc: 0.5775 - val_loss: 1.1038 - val_acc: 0.0000e+00\n",
      "565.2411863360358\n",
      "!!!!!!!!!  170  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 63ms/step - loss: 1.0935 - acc: 0.1761 - val_loss: 1.1677 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 191us/step - loss: 1.0747 - acc: 0.2394 - val_loss: 1.1774 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 60ms/step - loss: 1.0667 - acc: 0.7254 - val_loss: 1.1505 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 182us/step - loss: 1.0499 - acc: 0.7817 - val_loss: 1.1632 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 63ms/step - loss: 1.0594 - acc: 0.4366 - val_loss: 1.1168 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 205us/step - loss: 1.0359 - acc: 0.5986 - val_loss: 1.1337 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 65ms/step - loss: 1.0961 - acc: 0.4437 - val_loss: 1.0940 - val_acc: 0.5556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 182us/step - loss: 1.0768 - acc: 0.5493 - val_loss: 1.1098 - val_acc: 0.3056\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 65ms/step - loss: 1.0640 - acc: 0.7817 - val_loss: 1.1303 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.0457 - acc: 0.7958 - val_loss: 1.1440 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 65ms/step - loss: 1.1194 - acc: 0.3099 - val_loss: 1.2853 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 208us/step - loss: 1.1012 - acc: 0.4155 - val_loss: 1.2943 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 65ms/step - loss: 1.0649 - acc: 0.6056 - val_loss: 1.1553 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 239us/step - loss: 1.0397 - acc: 0.6479 - val_loss: 1.1768 - val_acc: 0.0000e+00\n",
      "634.4620429430336\n",
      "!!!!!!!!!  180  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 67ms/step - loss: 1.0880 - acc: 0.4930 - val_loss: 1.1201 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 196us/step - loss: 1.0688 - acc: 0.5141 - val_loss: 1.1323 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 9s 67ms/step - loss: 1.0858 - acc: 0.3310 - val_loss: 1.0129 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 208us/step - loss: 1.0676 - acc: 0.6056 - val_loss: 1.0320 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 69ms/step - loss: 1.0842 - acc: 0.5000 - val_loss: 1.0904 - val_acc: 0.3889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 189us/step - loss: 1.0599 - acc: 0.4930 - val_loss: 1.1056 - val_acc: 0.1111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 1.0384 - acc: 0.7324 - val_loss: 1.1849 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.0193 - acc: 0.7394 - val_loss: 1.1992 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 1.1010 - acc: 0.4718 - val_loss: 1.0752 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 190us/step - loss: 1.0768 - acc: 0.5352 - val_loss: 1.0866 - val_acc: 0.6111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 1.0647 - acc: 0.6901 - val_loss: 1.1603 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 183us/step - loss: 1.0531 - acc: 0.6972 - val_loss: 1.1721 - val_acc: 0.0000e+00\n",
      "698.4693557086287\n",
      "!!!!!!!!!  190  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 1.0919 - acc: 0.4859 - val_loss: 1.0863 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 176us/step - loss: 1.0826 - acc: 0.5493 - val_loss: 1.0873 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 1.0820 - acc: 0.4155 - val_loss: 1.1405 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 169us/step - loss: 1.0676 - acc: 0.4225 - val_loss: 1.1463 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 1.1207 - acc: 0.4085 - val_loss: 1.1384 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 288us/step - loss: 1.1004 - acc: 0.4859 - val_loss: 1.1453 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 1.1235 - acc: 0.2254 - val_loss: 1.0479 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 218us/step - loss: 1.1077 - acc: 0.3732 - val_loss: 1.0544 - val_acc: 0.9444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 1.0881 - acc: 0.4507 - val_loss: 1.1714 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 197us/step - loss: 1.0739 - acc: 0.4577 - val_loss: 1.1867 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 70ms/step - loss: 1.1188 - acc: 0.2606 - val_loss: 1.2059 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 211us/step - loss: 1.1028 - acc: 0.4225 - val_loss: 1.2041 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 1.0984 - acc: 0.4225 - val_loss: 1.2298 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 201us/step - loss: 1.0707 - acc: 0.4366 - val_loss: 1.2413 - val_acc: 0.0000e+00\n",
      "776.1344362956482\n",
      "!!!!!!!!!  200  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 1.0399 - acc: 0.4577 - val_loss: 1.0278 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 196us/step - loss: 1.0259 - acc: 0.5141 - val_loss: 1.0283 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 11s 75ms/step - loss: 1.0717 - acc: 0.5282 - val_loss: 1.0354 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 218us/step - loss: 1.0445 - acc: 0.5563 - val_loss: 1.0375 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 73ms/step - loss: 1.1652 - acc: 0.0352 - val_loss: 1.1085 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 257us/step - loss: 1.1435 - acc: 0.0704 - val_loss: 1.1084 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10s 72ms/step - loss: 1.1205 - acc: 0.2042 - val_loss: 1.1502 - val_acc: 0.1111\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 211us/step - loss: 1.1056 - acc: 0.4225 - val_loss: 1.1577 - val_acc: 0.1111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 11s 79ms/step - loss: 1.0564 - acc: 0.4648 - val_loss: 1.0319 - val_acc: 0.8333\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 225us/step - loss: 1.0338 - acc: 0.5000 - val_loss: 1.0426 - val_acc: 0.8056\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 12s 82ms/step - loss: 1.0909 - acc: 0.4366 - val_loss: 1.0984 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 239us/step - loss: 1.0740 - acc: 0.4859 - val_loss: 1.0966 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 12s 86ms/step - loss: 1.0985 - acc: 0.4014 - val_loss: 1.1628 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 211us/step - loss: 1.0770 - acc: 0.3873 - val_loss: 1.1704 - val_acc: 0.0000e+00\n",
      "858.1335322740101\n",
      "!!!!!!!!!  210  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 12s 83ms/step - loss: 1.0962 - acc: 0.4366 - val_loss: 1.1421 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 218us/step - loss: 1.0757 - acc: 0.4437 - val_loss: 1.1539 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 12s 87ms/step - loss: 1.1608 - acc: 0.0845 - val_loss: 1.0408 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 226us/step - loss: 1.1403 - acc: 0.0775 - val_loss: 1.0543 - val_acc: 0.8056\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 13s 89ms/step - loss: 1.1575 - acc: 0.4155 - val_loss: 1.1160 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 217us/step - loss: 1.1390 - acc: 0.4085 - val_loss: 1.1231 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 12s 81ms/step - loss: 0.9879 - acc: 0.5141 - val_loss: 1.1245 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 245us/step - loss: 0.9675 - acc: 0.5141 - val_loss: 1.1397 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 13s 91ms/step - loss: 1.1761 - acc: 0.4014 - val_loss: 1.0949 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 357us/step - loss: 1.1463 - acc: 0.3944 - val_loss: 1.1089 - val_acc: 0.3611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 12s 87ms/step - loss: 1.0390 - acc: 0.4437 - val_loss: 1.1610 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 232us/step - loss: 1.0251 - acc: 0.5704 - val_loss: 1.1770 - val_acc: 0.0000e+00\n",
      "937.0025953699068\n",
      "!!!!!!!!!  220  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 13s 92ms/step - loss: 1.0975 - acc: 0.1690 - val_loss: 0.9860 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 365us/step - loss: 1.0739 - acc: 0.3521 - val_loss: 0.9959 - val_acc: 0.8056\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 1.0356 - acc: 0.5493 - val_loss: 1.0964 - val_acc: 0.4722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 218us/step - loss: 1.0164 - acc: 0.5704 - val_loss: 1.1135 - val_acc: 0.3889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 1.1270 - acc: 0.2324 - val_loss: 1.1538 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 365us/step - loss: 1.1054 - acc: 0.2535 - val_loss: 1.1675 - val_acc: 0.0556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 13s 94ms/step - loss: 1.1149 - acc: 0.3451 - val_loss: 1.1849 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 232us/step - loss: 1.0919 - acc: 0.4014 - val_loss: 1.2140 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 13s 93ms/step - loss: 1.0777 - acc: 0.5000 - val_loss: 1.1148 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 239us/step - loss: 1.0585 - acc: 0.6197 - val_loss: 1.1284 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 1.0593 - acc: 0.4930 - val_loss: 1.1262 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 246us/step - loss: 1.0408 - acc: 0.6056 - val_loss: 1.1441 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 97ms/step - loss: 1.0750 - acc: 0.4437 - val_loss: 1.0921 - val_acc: 0.1667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 358us/step - loss: 1.0525 - acc: 0.5211 - val_loss: 1.1135 - val_acc: 0.0278\n",
      "1036.3127287632408\n",
      "!!!!!!!!!  230  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 14s 97ms/step - loss: 1.0982 - acc: 0.3028 - val_loss: 1.2470 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 400us/step - loss: 1.0751 - acc: 0.4859 - val_loss: 1.2662 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 98ms/step - loss: 1.0568 - acc: 0.5070 - val_loss: 1.1094 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 239us/step - loss: 1.0335 - acc: 0.6338 - val_loss: 1.1346 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 99ms/step - loss: 1.0825 - acc: 0.5000 - val_loss: 1.1315 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 261us/step - loss: 1.0639 - acc: 0.5141 - val_loss: 1.1548 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 96ms/step - loss: 1.0585 - acc: 0.7042 - val_loss: 1.2051 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 400us/step - loss: 1.0386 - acc: 0.7676 - val_loss: 1.2239 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 1.0255 - acc: 0.7465 - val_loss: 1.2266 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 288us/step - loss: 1.0087 - acc: 0.7465 - val_loss: 1.2555 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 100ms/step - loss: 1.0708 - acc: 0.3451 - val_loss: 1.0892 - val_acc: 0.3889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 274us/step - loss: 1.0541 - acc: 0.5070 - val_loss: 1.1058 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 103ms/step - loss: 1.1251 - acc: 0.2113 - val_loss: 1.0228 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 275us/step - loss: 1.1058 - acc: 0.2183 - val_loss: 1.0489 - val_acc: 0.7500\n",
      "1141.8579883749892\n",
      "!!!!!!!!!  240  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 1.0737 - acc: 0.5282 - val_loss: 1.1423 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 449us/step - loss: 1.0581 - acc: 0.5775 - val_loss: 1.1596 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 97ms/step - loss: 1.1077 - acc: 0.3380 - val_loss: 1.0646 - val_acc: 0.5556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 253us/step - loss: 1.0906 - acc: 0.3944 - val_loss: 1.0836 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 98ms/step - loss: 1.0814 - acc: 0.4225 - val_loss: 1.1774 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 253us/step - loss: 1.0678 - acc: 0.4577 - val_loss: 1.1804 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 106ms/step - loss: 1.0408 - acc: 0.6620 - val_loss: 1.0849 - val_acc: 0.1389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 274us/step - loss: 1.0205 - acc: 0.6972 - val_loss: 1.1039 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 106ms/step - loss: 1.1400 - acc: 0.2113 - val_loss: 1.0141 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 274us/step - loss: 1.1184 - acc: 0.2958 - val_loss: 1.0326 - val_acc: 0.8056\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 99ms/step - loss: 1.1115 - acc: 0.4437 - val_loss: 1.0786 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 429us/step - loss: 1.0848 - acc: 0.4577 - val_loss: 1.1013 - val_acc: 0.0000e+00\n",
      "1233.2784171489147\n",
      "!!!!!!!!!  250  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 103ms/step - loss: 1.1114 - acc: 0.5000 - val_loss: 1.1563 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 260us/step - loss: 1.0876 - acc: 0.5000 - val_loss: 1.1724 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 110ms/step - loss: 1.0987 - acc: 0.4366 - val_loss: 1.1494 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 449us/step - loss: 1.0798 - acc: 0.4930 - val_loss: 1.1681 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 111ms/step - loss: 1.1154 - acc: 0.4648 - val_loss: 1.2074 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0804 - acc: 0.4930 - val_loss: 1.2263 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 112ms/step - loss: 1.1115 - acc: 0.3944 - val_loss: 1.0529 - val_acc: 0.6944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 267us/step - loss: 1.0899 - acc: 0.4577 - val_loss: 1.0592 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 1.0137 - acc: 0.7113 - val_loss: 1.2172 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.9942 - acc: 0.7183 - val_loss: 1.2345 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 111ms/step - loss: 1.0328 - acc: 0.5352 - val_loss: 1.1326 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 442us/step - loss: 1.0063 - acc: 0.6056 - val_loss: 1.1468 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 115ms/step - loss: 1.1401 - acc: 0.4718 - val_loss: 1.1129 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 281us/step - loss: 1.1178 - acc: 0.4859 - val_loss: 1.1284 - val_acc: 0.0000e+00\n",
      "1349.8398732983953\n",
      "!!!!!!!!!  260  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 115ms/step - loss: 1.0412 - acc: 0.5000 - val_loss: 1.1549 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 260us/step - loss: 1.0142 - acc: 0.5000 - val_loss: 1.1764 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 115ms/step - loss: 1.1132 - acc: 0.3732 - val_loss: 1.1276 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 337us/step - loss: 1.0945 - acc: 0.4366 - val_loss: 1.1365 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 116ms/step - loss: 1.1134 - acc: 0.2887 - val_loss: 1.0716 - val_acc: 0.5833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 274us/step - loss: 1.0855 - acc: 0.6408 - val_loss: 1.0857 - val_acc: 0.3056\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 1.0932 - acc: 0.2535 - val_loss: 1.0889 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 400us/step - loss: 1.0719 - acc: 0.6761 - val_loss: 1.1042 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 118ms/step - loss: 1.0908 - acc: 0.1901 - val_loss: 1.0854 - val_acc: 0.3333\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 288us/step - loss: 1.0639 - acc: 0.7042 - val_loss: 1.1116 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 119ms/step - loss: 1.0329 - acc: 0.5000 - val_loss: 1.2127 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 288us/step - loss: 1.0045 - acc: 0.5000 - val_loss: 1.2451 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 120ms/step - loss: 1.1080 - acc: 0.0845 - val_loss: 1.0441 - val_acc: 0.8333\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0849 - acc: 0.3028 - val_loss: 1.0606 - val_acc: 0.4444\n",
      "1472.06538749489\n",
      "!!!!!!!!!  270  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 122ms/step - loss: 1.1672 - acc: 0.1479 - val_loss: 1.0788 - val_acc: 0.4167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 302us/step - loss: 1.1367 - acc: 0.2324 - val_loss: 1.0910 - val_acc: 0.3611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 121ms/step - loss: 1.1169 - acc: 0.0915 - val_loss: 1.0436 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0981 - acc: 0.1620 - val_loss: 1.0575 - val_acc: 0.9444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 131ms/step - loss: 1.0432 - acc: 0.7746 - val_loss: 1.2205 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 407us/step - loss: 1.0150 - acc: 0.8310 - val_loss: 1.2449 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 131ms/step - loss: 1.1234 - acc: 0.0986 - val_loss: 1.0505 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 372us/step - loss: 1.0925 - acc: 0.2465 - val_loss: 1.0682 - val_acc: 0.5833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 134ms/step - loss: 1.0986 - acc: 0.2465 - val_loss: 1.2136 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 456us/step - loss: 1.0825 - acc: 0.5000 - val_loss: 1.2162 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 133ms/step - loss: 1.0879 - acc: 0.3521 - val_loss: 1.1872 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 456us/step - loss: 1.0710 - acc: 0.5000 - val_loss: 1.2005 - val_acc: 0.0000e+00\n",
      "1587.251566721647\n",
      "!!!!!!!!!  280  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 1.0790 - acc: 0.3239 - val_loss: 1.2527 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 421us/step - loss: 1.0548 - acc: 0.4155 - val_loss: 1.2669 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 1.0809 - acc: 0.4577 - val_loss: 1.1419 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 365us/step - loss: 1.0549 - acc: 0.5775 - val_loss: 1.1674 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 125ms/step - loss: 1.0799 - acc: 0.5282 - val_loss: 1.2976 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 384us/step - loss: 1.0604 - acc: 0.6831 - val_loss: 1.3217 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 1.0769 - acc: 0.4930 - val_loss: 1.1169 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 486us/step - loss: 1.0535 - acc: 0.5000 - val_loss: 1.1424 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 141ms/step - loss: 1.1693 - acc: 0.0986 - val_loss: 1.1580 - val_acc: 0.1944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 451us/step - loss: 1.1392 - acc: 0.1268 - val_loss: 1.1742 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 142ms/step - loss: 1.1023 - acc: 0.3380 - val_loss: 1.1136 - val_acc: 0.1667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 407us/step - loss: 1.0792 - acc: 0.5282 - val_loss: 1.1271 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 140ms/step - loss: 1.0993 - acc: 0.3028 - val_loss: 0.9138 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 421us/step - loss: 1.0792 - acc: 0.5423 - val_loss: 0.9184 - val_acc: 0.9722\n",
      "1729.8148619115152\n",
      "!!!!!!!!!  290  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 144ms/step - loss: 1.0986 - acc: 0.3169 - val_loss: 1.0263 - val_acc: 0.7778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 516us/step - loss: 1.0783 - acc: 0.5282 - val_loss: 1.0373 - val_acc: 0.7778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 143ms/step - loss: 1.1231 - acc: 0.1690 - val_loss: 1.0340 - val_acc: 0.3611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 421us/step - loss: 1.1070 - acc: 0.3592 - val_loss: 1.0332 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 1.1251 - acc: 0.1479 - val_loss: 1.2894 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 373us/step - loss: 1.1040 - acc: 0.2817 - val_loss: 1.2889 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 137ms/step - loss: 1.0599 - acc: 0.6056 - val_loss: 1.1617 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 407us/step - loss: 1.0285 - acc: 0.7465 - val_loss: 1.1755 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 1.1595 - acc: 0.0915 - val_loss: 0.9938 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 267us/step - loss: 1.1373 - acc: 0.1338 - val_loss: 1.0057 - val_acc: 0.9444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 144ms/step - loss: 1.1253 - acc: 0.1549 - val_loss: 1.0300 - val_acc: 0.7778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 485us/step - loss: 1.1022 - acc: 0.3099 - val_loss: 1.0420 - val_acc: 0.7778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 150ms/step - loss: 1.0179 - acc: 0.6972 - val_loss: 1.1020 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 491us/step - loss: 0.9963 - acc: 0.7042 - val_loss: 1.1046 - val_acc: 0.0000e+00\n",
      "1880.9218690455916\n",
      "!!!!!!!!!  300  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 151ms/step - loss: 1.0792 - acc: 0.3310 - val_loss: 0.9972 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 533us/step - loss: 1.0575 - acc: 0.5563 - val_loss: 0.9994 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 153ms/step - loss: 1.0195 - acc: 0.5211 - val_loss: 1.1138 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 478us/step - loss: 1.0007 - acc: 0.5352 - val_loss: 1.1178 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 155ms/step - loss: 1.1199 - acc: 0.0915 - val_loss: 0.9507 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 526us/step - loss: 1.0991 - acc: 0.3732 - val_loss: 0.9586 - val_acc: 1.0000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 155ms/step - loss: 1.0988 - acc: 0.3803 - val_loss: 1.1542 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 527us/step - loss: 1.0832 - acc: 0.4930 - val_loss: 1.1600 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 22s 158ms/step - loss: 1.0915 - acc: 0.4155 - val_loss: 1.1291 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 386us/step - loss: 1.0738 - acc: 0.4155 - val_loss: 1.1310 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 153ms/step - loss: 1.1390 - acc: 0.0845 - val_loss: 1.0484 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 422us/step - loss: 1.1206 - acc: 0.1197 - val_loss: 1.0541 - val_acc: 0.7222\n",
      "2018.4103838864614\n",
      "!!!!!!!!!  310  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 1.1284 - acc: 0.4155 - val_loss: 1.1388 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 448us/step - loss: 1.1011 - acc: 0.4085 - val_loss: 1.1510 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.0936 - acc: 0.3592 - val_loss: 1.1273 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 571us/step - loss: 1.0715 - acc: 0.4507 - val_loss: 1.1435 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 157ms/step - loss: 1.0800 - acc: 0.5000 - val_loss: 1.1754 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 415us/step - loss: 1.0651 - acc: 0.5000 - val_loss: 1.1920 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.1324 - acc: 0.1127 - val_loss: 1.1089 - val_acc: 0.1111\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 492us/step - loss: 1.1139 - acc: 0.3169 - val_loss: 1.1250 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 1.0547 - acc: 0.4507 - val_loss: 1.1237 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 492us/step - loss: 1.0391 - acc: 0.5070 - val_loss: 1.1384 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 165ms/step - loss: 1.1296 - acc: 0.0845 - val_loss: 1.0880 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 519us/step - loss: 1.1122 - acc: 0.1197 - val_loss: 1.1087 - val_acc: 0.3611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 1.0322 - acc: 0.5211 - val_loss: 1.0426 - val_acc: 0.6389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 442us/step - loss: 1.0127 - acc: 0.5070 - val_loss: 1.0702 - val_acc: 0.5833\n",
      "2185.376804897981\n",
      "!!!!!!!!!  320  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 1.0476 - acc: 0.5000 - val_loss: 1.1554 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 436us/step - loss: 1.0310 - acc: 0.5000 - val_loss: 1.1766 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 169ms/step - loss: 1.0335 - acc: 0.4930 - val_loss: 1.2179 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 569us/step - loss: 1.0196 - acc: 0.5070 - val_loss: 1.2468 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 169ms/step - loss: 1.0983 - acc: 0.3028 - val_loss: 1.0225 - val_acc: 0.6944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 498us/step - loss: 1.0869 - acc: 0.4507 - val_loss: 1.0329 - val_acc: 0.6389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 172ms/step - loss: 1.1135 - acc: 0.0845 - val_loss: 1.1669 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 612us/step - loss: 1.0944 - acc: 0.2254 - val_loss: 1.1863 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 172ms/step - loss: 1.0985 - acc: 0.4930 - val_loss: 1.1568 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 541us/step - loss: 1.0811 - acc: 0.5000 - val_loss: 1.1733 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 174ms/step - loss: 1.1052 - acc: 0.3169 - val_loss: 1.0524 - val_acc: 0.6944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 541us/step - loss: 1.0944 - acc: 0.5070 - val_loss: 1.0648 - val_acc: 0.5833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 173ms/step - loss: 1.1083 - acc: 0.1268 - val_loss: 1.1200 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 505us/step - loss: 1.0889 - acc: 0.4155 - val_loss: 1.1425 - val_acc: 0.0000e+00\n",
      "2362.097878302423\n",
      "!!!!!!!!!  330  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 173ms/step - loss: 1.1158 - acc: 0.0845 - val_loss: 0.9953 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 492us/step - loss: 1.0995 - acc: 0.4577 - val_loss: 1.0057 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 175ms/step - loss: 1.0844 - acc: 0.5352 - val_loss: 1.1770 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 520us/step - loss: 1.0703 - acc: 0.5282 - val_loss: 1.1892 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 828s 6s/step - loss: 1.0834 - acc: 0.4366 - val_loss: 1.1208 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0633 - acc: 0.5845 - val_loss: 1.1334 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 129ms/step - loss: 1.0881 - acc: 0.4155 - val_loss: 1.1077 - val_acc: 0.3056\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 520us/step - loss: 1.0713 - acc: 0.4155 - val_loss: 1.1224 - val_acc: 0.2500\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 107ms/step - loss: 1.0837 - acc: 0.4930 - val_loss: 1.0555 - val_acc: 0.7778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0674 - acc: 0.5423 - val_loss: 1.0721 - val_acc: 0.5556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 103ms/step - loss: 1.0358 - acc: 0.4155 - val_loss: 1.3188 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 351us/step - loss: 1.0164 - acc: 0.4155 - val_loss: 1.3322 - val_acc: 0.0000e+00\n",
      "3296.2658651421434\n",
      "!!!!!!!!!  340  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 100ms/step - loss: 1.0629 - acc: 0.4155 - val_loss: 1.1517 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 330us/step - loss: 1.0469 - acc: 0.4225 - val_loss: 1.1588 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 98ms/step - loss: 1.0945 - acc: 0.4437 - val_loss: 1.0616 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0724 - acc: 0.4930 - val_loss: 1.0691 - val_acc: 0.7222\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 1.1015 - acc: 0.2535 - val_loss: 1.0672 - val_acc: 0.7778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 344us/step - loss: 1.0858 - acc: 0.5352 - val_loss: 1.0744 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 100ms/step - loss: 1.2050 - acc: 0.0634 - val_loss: 1.0449 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 344us/step - loss: 1.1716 - acc: 0.0634 - val_loss: 1.0498 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 99ms/step - loss: 1.0371 - acc: 0.5000 - val_loss: 1.1690 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 323us/step - loss: 1.0183 - acc: 0.5000 - val_loss: 1.1753 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 105ms/step - loss: 1.0847 - acc: 0.4859 - val_loss: 0.9516 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 281us/step - loss: 1.0624 - acc: 0.4789 - val_loss: 0.9437 - val_acc: 0.9167\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 101ms/step - loss: 1.0975 - acc: 0.4155 - val_loss: 1.2411 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 316us/step - loss: 1.0775 - acc: 0.4296 - val_loss: 1.2428 - val_acc: 0.0000e+00\n",
      "3399.8735708052427\n",
      "!!!!!!!!!  350  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 14s 102ms/step - loss: 0.9903 - acc: 0.5493 - val_loss: 1.2113 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.9658 - acc: 0.6408 - val_loss: 1.2183 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 102ms/step - loss: 1.1756 - acc: 0.0211 - val_loss: 1.1075 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 323us/step - loss: 1.1533 - acc: 0.0141 - val_loss: 1.1070 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 104ms/step - loss: 1.0986 - acc: 0.3732 - val_loss: 1.1389 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0669 - acc: 0.4366 - val_loss: 1.1450 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 104ms/step - loss: 1.0762 - acc: 0.4648 - val_loss: 1.1332 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 288us/step - loss: 1.0535 - acc: 0.5493 - val_loss: 1.1319 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 104ms/step - loss: 1.0697 - acc: 0.5282 - val_loss: 1.0730 - val_acc: 0.6667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 295us/step - loss: 1.0483 - acc: 0.5211 - val_loss: 1.0747 - val_acc: 0.5000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 107ms/step - loss: 1.0555 - acc: 0.5000 - val_loss: 1.1831 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 330us/step - loss: 1.0338 - acc: 0.5000 - val_loss: 1.1874 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 105ms/step - loss: 1.0023 - acc: 0.6831 - val_loss: 1.0375 - val_acc: 0.7222\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 323us/step - loss: 0.9708 - acc: 0.6972 - val_loss: 1.0392 - val_acc: 0.7222\n",
      "3506.846417700299\n",
      "!!!!!!!!!  360  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 107ms/step - loss: 1.1052 - acc: 0.2465 - val_loss: 1.0993 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 323us/step - loss: 1.0892 - acc: 0.3873 - val_loss: 1.0917 - val_acc: 0.2778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 106ms/step - loss: 1.0919 - acc: 0.4085 - val_loss: 1.0963 - val_acc: 0.1389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0738 - acc: 0.4718 - val_loss: 1.0985 - val_acc: 0.1111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 108ms/step - loss: 1.0758 - acc: 0.4296 - val_loss: 1.0899 - val_acc: 0.1667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0622 - acc: 0.5000 - val_loss: 1.0875 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 108ms/step - loss: 1.0975 - acc: 0.5211 - val_loss: 1.0389 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0779 - acc: 0.5282 - val_loss: 1.0477 - val_acc: 0.8611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15s 109ms/step - loss: 1.0419 - acc: 0.5282 - val_loss: 1.1724 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 323us/step - loss: 1.0242 - acc: 0.5634 - val_loss: 1.1603 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 110ms/step - loss: 1.1033 - acc: 0.5000 - val_loss: 1.1672 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 324us/step - loss: 1.0824 - acc: 0.5000 - val_loss: 1.1676 - val_acc: 0.0000e+00\n",
      "3601.8806571095884\n",
      "!!!!!!!!!  370  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 116ms/step - loss: 1.0762 - acc: 0.4437 - val_loss: 1.0779 - val_acc: 0.9444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 379us/step - loss: 1.0533 - acc: 0.4577 - val_loss: 1.0826 - val_acc: 0.6111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 115ms/step - loss: 1.1167 - acc: 0.3732 - val_loss: 1.1785 - val_acc: 0.1389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 352us/step - loss: 1.0958 - acc: 0.4296 - val_loss: 1.1811 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 1.0875 - acc: 0.4366 - val_loss: 1.1992 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 337us/step - loss: 1.0656 - acc: 0.4718 - val_loss: 1.1922 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 110ms/step - loss: 1.0269 - acc: 0.5141 - val_loss: 1.0998 - val_acc: 0.3611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 372us/step - loss: 1.0083 - acc: 0.5141 - val_loss: 1.1014 - val_acc: 0.2222\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 1.0742 - acc: 0.5000 - val_loss: 1.2525 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 344us/step - loss: 1.0554 - acc: 0.5000 - val_loss: 1.2512 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 1.1123 - acc: 0.4014 - val_loss: 1.2124 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 393us/step - loss: 1.0990 - acc: 0.4155 - val_loss: 1.1977 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 113ms/step - loss: 1.0804 - acc: 0.5563 - val_loss: 1.0598 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 323us/step - loss: 1.0678 - acc: 0.5563 - val_loss: 1.0550 - val_acc: 0.9722\n",
      "3719.2897916301235\n",
      "!!!!!!!!!  380  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 115ms/step - loss: 1.0511 - acc: 0.5211 - val_loss: 1.0876 - val_acc: 0.1944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0304 - acc: 0.5282 - val_loss: 1.0741 - val_acc: 0.2222\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 16s 116ms/step - loss: 1.0688 - acc: 0.4437 - val_loss: 1.0446 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 372us/step - loss: 1.0506 - acc: 0.4859 - val_loss: 1.0457 - val_acc: 0.2778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 16s 115ms/step - loss: 1.1364 - acc: 0.0845 - val_loss: 0.8728 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 351us/step - loss: 1.1117 - acc: 0.2394 - val_loss: 0.8620 - val_acc: 1.0000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 117ms/step - loss: 1.1186 - acc: 0.4155 - val_loss: 1.1467 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 323us/step - loss: 1.1024 - acc: 0.4648 - val_loss: 1.1482 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 119ms/step - loss: 1.0672 - acc: 0.4859 - val_loss: 1.1176 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 309us/step - loss: 1.0473 - acc: 0.4859 - val_loss: 1.1247 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 119ms/step - loss: 1.0721 - acc: 0.5000 - val_loss: 1.0585 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 344us/step - loss: 1.0540 - acc: 0.5000 - val_loss: 1.0530 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 17s 120ms/step - loss: 1.1282 - acc: 0.1056 - val_loss: 1.1116 - val_acc: 0.4167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 351us/step - loss: 1.1083 - acc: 0.2183 - val_loss: 1.0999 - val_acc: 0.4444\n",
      "3839.5117087030044\n",
      "!!!!!!!!!  390  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 125ms/step - loss: 1.0711 - acc: 0.4648 - val_loss: 1.1175 - val_acc: 0.1111\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 344us/step - loss: 1.0578 - acc: 0.5000 - val_loss: 1.1247 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 124ms/step - loss: 1.1191 - acc: 0.3169 - val_loss: 1.1955 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 386us/step - loss: 1.1059 - acc: 0.3944 - val_loss: 1.1868 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 124ms/step - loss: 1.0974 - acc: 0.4366 - val_loss: 1.1870 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 351us/step - loss: 1.0832 - acc: 0.4648 - val_loss: 1.1595 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 125ms/step - loss: 1.1523 - acc: 0.0845 - val_loss: 1.0379 - val_acc: 0.6944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 379us/step - loss: 1.1225 - acc: 0.1761 - val_loss: 1.0491 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 126ms/step - loss: 1.0541 - acc: 0.4437 - val_loss: 1.0590 - val_acc: 0.6667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 436us/step - loss: 1.0384 - acc: 0.4859 - val_loss: 1.0671 - val_acc: 0.5556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 126ms/step - loss: 1.0712 - acc: 0.5070 - val_loss: 1.1955 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 316us/step - loss: 1.0536 - acc: 0.5282 - val_loss: 1.1936 - val_acc: 0.0000e+00\n",
      "3949.091050915126\n",
      "!!!!!!!!!  400  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 127ms/step - loss: 1.1285 - acc: 0.1127 - val_loss: 1.0687 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 379us/step - loss: 1.1019 - acc: 0.2535 - val_loss: 1.0730 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 127ms/step - loss: 1.1238 - acc: 0.1972 - val_loss: 1.1590 - val_acc: 0.1111\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 393us/step - loss: 1.1033 - acc: 0.3732 - val_loss: 1.1660 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 127ms/step - loss: 1.1255 - acc: 0.0915 - val_loss: 1.1234 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 372us/step - loss: 1.1075 - acc: 0.2324 - val_loss: 1.1034 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 18s 129ms/step - loss: 1.0594 - acc: 0.5282 - val_loss: 0.9249 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 337us/step - loss: 1.0446 - acc: 0.5563 - val_loss: 0.9236 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 139ms/step - loss: 1.0854 - acc: 0.4437 - val_loss: 1.0871 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 379us/step - loss: 1.0723 - acc: 0.4930 - val_loss: 1.0894 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 131ms/step - loss: 1.1311 - acc: 0.1197 - val_loss: 1.0478 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 344us/step - loss: 1.1151 - acc: 0.2183 - val_loss: 1.0517 - val_acc: 0.9444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 140ms/step - loss: 1.0954 - acc: 0.4296 - val_loss: 1.2404 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 414us/step - loss: 1.0800 - acc: 0.4859 - val_loss: 1.2429 - val_acc: 0.0000e+00\n",
      "4083.1244329807805\n",
      "!!!!!!!!!  410  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 132ms/step - loss: 1.0866 - acc: 0.4296 - val_loss: 1.2640 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 330us/step - loss: 1.0734 - acc: 0.4296 - val_loss: 1.2605 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 133ms/step - loss: 1.0998 - acc: 0.3521 - val_loss: 1.0626 - val_acc: 0.5278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 428us/step - loss: 1.0813 - acc: 0.4366 - val_loss: 1.0778 - val_acc: 0.4444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 133ms/step - loss: 1.1034 - acc: 0.4507 - val_loss: 1.0224 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 372us/step - loss: 1.0871 - acc: 0.4437 - val_loss: 1.0185 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 1.0851 - acc: 0.5070 - val_loss: 1.0739 - val_acc: 0.5556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 393us/step - loss: 1.0691 - acc: 0.5493 - val_loss: 1.0843 - val_acc: 0.4444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 137ms/step - loss: 1.1022 - acc: 0.3662 - val_loss: 0.9774 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 379us/step - loss: 1.0869 - acc: 0.3521 - val_loss: 0.9886 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 1.0957 - acc: 0.4507 - val_loss: 0.9835 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 407us/step - loss: 1.0833 - acc: 0.4789 - val_loss: 0.9950 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 137ms/step - loss: 1.0887 - acc: 0.5493 - val_loss: 1.1208 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 408us/step - loss: 1.0763 - acc: 0.5423 - val_loss: 1.1275 - val_acc: 0.0000e+00\n",
      "4220.667966235758\n",
      "!!!!!!!!!  420  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 1.0975 - acc: 0.5000 - val_loss: 1.1365 - val_acc: 0.1111\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 358us/step - loss: 1.0890 - acc: 0.5211 - val_loss: 1.1469 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 19s 136ms/step - loss: 1.1023 - acc: 0.3451 - val_loss: 1.0888 - val_acc: 0.3611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 414us/step - loss: 1.0865 - acc: 0.4296 - val_loss: 1.0969 - val_acc: 0.3611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 139ms/step - loss: 1.0730 - acc: 0.4155 - val_loss: 1.1796 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 407us/step - loss: 1.0565 - acc: 0.4085 - val_loss: 1.1884 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 139ms/step - loss: 1.1258 - acc: 0.1831 - val_loss: 1.0956 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 435us/step - loss: 1.1087 - acc: 0.2254 - val_loss: 1.1009 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 140ms/step - loss: 1.0923 - acc: 0.3239 - val_loss: 1.1975 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 414us/step - loss: 1.0707 - acc: 0.3099 - val_loss: 1.2059 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 142ms/step - loss: 1.0784 - acc: 0.4085 - val_loss: 1.0587 - val_acc: 0.5833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 379us/step - loss: 1.0599 - acc: 0.4718 - val_loss: 1.0673 - val_acc: 0.5556\n",
      "4342.202147844552\n",
      "!!!!!!!!!  430  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 20s 143ms/step - loss: 1.0832 - acc: 0.4225 - val_loss: 1.2341 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 393us/step - loss: 1.0618 - acc: 0.5845 - val_loss: 1.2495 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 1.0839 - acc: 0.4648 - val_loss: 1.1241 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 379us/step - loss: 1.0738 - acc: 0.4859 - val_loss: 1.1315 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 1.1257 - acc: 0.1620 - val_loss: 1.0874 - val_acc: 0.4167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 407us/step - loss: 1.1114 - acc: 0.1761 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 146ms/step - loss: 1.1137 - acc: 0.4155 - val_loss: 1.0932 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 414us/step - loss: 1.0918 - acc: 0.4085 - val_loss: 1.0990 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 145ms/step - loss: 1.1238 - acc: 0.1761 - val_loss: 1.0259 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 429us/step - loss: 1.1042 - acc: 0.3521 - val_loss: 1.0393 - val_acc: 0.7778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 148ms/step - loss: 1.0476 - acc: 0.4859 - val_loss: 1.1306 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 435us/step - loss: 1.0280 - acc: 0.5282 - val_loss: 1.1497 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 146ms/step - loss: 1.1062 - acc: 0.1690 - val_loss: 1.0596 - val_acc: 0.7222\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 477us/step - loss: 1.0930 - acc: 0.4296 - val_loss: 1.0664 - val_acc: 0.7222\n",
      "4490.379817452541\n",
      "!!!!!!!!!  440  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 148ms/step - loss: 1.1217 - acc: 0.3873 - val_loss: 1.1098 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 386us/step - loss: 1.1045 - acc: 0.4155 - val_loss: 1.1257 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 148ms/step - loss: 1.0936 - acc: 0.3803 - val_loss: 1.0870 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 446us/step - loss: 1.0684 - acc: 0.5704 - val_loss: 1.1079 - val_acc: 0.2500\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 146ms/step - loss: 1.0958 - acc: 0.4648 - val_loss: 1.0926 - val_acc: 0.4722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 421us/step - loss: 1.0743 - acc: 0.5000 - val_loss: 1.0950 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 149ms/step - loss: 1.0498 - acc: 0.5493 - val_loss: 1.1311 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 372us/step - loss: 1.0339 - acc: 0.5423 - val_loss: 1.1466 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 152ms/step - loss: 1.1631 - acc: 0.2676 - val_loss: 1.0923 - val_acc: 0.3889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 463us/step - loss: 1.1475 - acc: 0.3803 - val_loss: 1.1122 - val_acc: 0.2500\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 21s 149ms/step - loss: 1.0222 - acc: 0.5915 - val_loss: 1.0144 - val_acc: 0.6944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 434us/step - loss: 0.9994 - acc: 0.6338 - val_loss: 1.0334 - val_acc: 0.6389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 152ms/step - loss: 1.1214 - acc: 0.1549 - val_loss: 1.0565 - val_acc: 0.7222\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 457us/step - loss: 1.1018 - acc: 0.2183 - val_loss: 1.0648 - val_acc: 0.8056\n",
      "4642.177447887474\n",
      "!!!!!!!!!  450  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 154ms/step - loss: 1.0337 - acc: 0.5000 - val_loss: 1.1040 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 450us/step - loss: 1.0143 - acc: 0.5070 - val_loss: 1.1209 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 153ms/step - loss: 1.0933 - acc: 0.4014 - val_loss: 1.0976 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 386us/step - loss: 1.0687 - acc: 0.5352 - val_loss: 1.0999 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 152ms/step - loss: 1.0856 - acc: 0.4014 - val_loss: 1.0670 - val_acc: 0.4444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 450us/step - loss: 1.0689 - acc: 0.4085 - val_loss: 1.0777 - val_acc: 0.3889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 154ms/step - loss: 1.0515 - acc: 0.4930 - val_loss: 1.1964 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 443us/step - loss: 1.0282 - acc: 0.5000 - val_loss: 1.2179 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 156ms/step - loss: 1.0855 - acc: 0.0634 - val_loss: 1.0815 - val_acc: 0.3611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 393us/step - loss: 1.0726 - acc: 0.1268 - val_loss: 1.0834 - val_acc: 0.1944\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 22s 156ms/step - loss: 1.0964 - acc: 0.4014 - val_loss: 1.1171 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 435us/step - loss: 1.0814 - acc: 0.4648 - val_loss: 1.1214 - val_acc: 0.0000e+00\n",
      "4776.606604353964\n",
      "!!!!!!!!!  460  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 22s 157ms/step - loss: 1.0809 - acc: 0.4085 - val_loss: 1.0522 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 463us/step - loss: 1.0633 - acc: 0.4225 - val_loss: 1.0593 - val_acc: 0.6944\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 1.1581 - acc: 0.1690 - val_loss: 1.0668 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 484us/step - loss: 1.1391 - acc: 0.2113 - val_loss: 1.0756 - val_acc: 0.5833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.0857 - acc: 0.4155 - val_loss: 1.1344 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 393us/step - loss: 1.0687 - acc: 0.5493 - val_loss: 1.1412 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 1.1493 - acc: 0.1056 - val_loss: 1.0423 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 450us/step - loss: 1.1262 - acc: 0.1972 - val_loss: 1.0555 - val_acc: 0.7500\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 1.0769 - acc: 0.2746 - val_loss: 1.2488 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 442us/step - loss: 1.0511 - acc: 0.2535 - val_loss: 1.2794 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 160ms/step - loss: 1.1184 - acc: 0.0423 - val_loss: 1.0523 - val_acc: 0.6111\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 484us/step - loss: 1.1005 - acc: 0.0634 - val_loss: 1.0564 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.1313 - acc: 0.3732 - val_loss: 1.1219 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 493us/step - loss: 1.1044 - acc: 0.4014 - val_loss: 1.1300 - val_acc: 0.0000e+00\n",
      "4940.276518667008\n",
      "!!!!!!!!!  470  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.0754 - acc: 0.4648 - val_loss: 1.1178 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 449us/step - loss: 1.0540 - acc: 0.7183 - val_loss: 1.1285 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 164ms/step - loss: 1.0136 - acc: 0.5211 - val_loss: 1.0951 - val_acc: 0.4444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 442us/step - loss: 0.9815 - acc: 0.5070 - val_loss: 1.1120 - val_acc: 0.1944\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 164ms/step - loss: 1.0867 - acc: 0.4296 - val_loss: 1.1371 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 407us/step - loss: 1.0651 - acc: 0.5211 - val_loss: 1.1478 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 23s 165ms/step - loss: 0.9760 - acc: 0.7113 - val_loss: 1.1846 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 415us/step - loss: 0.9525 - acc: 0.7324 - val_loss: 1.1997 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 176ms/step - loss: 1.0902 - acc: 0.3944 - val_loss: 1.0410 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 457us/step - loss: 1.0651 - acc: 0.6690 - val_loss: 1.0522 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 171ms/step - loss: 1.1742 - acc: 0.0775 - val_loss: 1.0373 - val_acc: 0.9444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 471us/step - loss: 1.1537 - acc: 0.0634 - val_loss: 1.0432 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 168ms/step - loss: 1.0283 - acc: 0.5211 - val_loss: 1.1524 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 485us/step - loss: 0.9990 - acc: 0.5563 - val_loss: 1.1694 - val_acc: 0.0000e+00\n",
      "5109.887670844227\n",
      "!!!!!!!!!  480  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 170ms/step - loss: 1.1672 - acc: 0.0845 - val_loss: 0.9780 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 485us/step - loss: 1.1358 - acc: 0.0634 - val_loss: 0.9899 - val_acc: 0.8611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 171ms/step - loss: 1.0927 - acc: 0.4155 - val_loss: 1.2306 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 484us/step - loss: 1.0731 - acc: 0.4155 - val_loss: 1.2480 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 24s 172ms/step - loss: 1.0750 - acc: 0.5423 - val_loss: 1.1520 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 435us/step - loss: 1.0547 - acc: 0.8521 - val_loss: 1.1666 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 173ms/step - loss: 1.0305 - acc: 0.5211 - val_loss: 1.1676 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 471us/step - loss: 1.0112 - acc: 0.5423 - val_loss: 1.1827 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 191ms/step - loss: 1.0943 - acc: 0.4085 - val_loss: 1.0837 - val_acc: 0.5278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 660us/step - loss: 1.0748 - acc: 0.5070 - val_loss: 1.0964 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 26s 186ms/step - loss: 1.1208 - acc: 0.0915 - val_loss: 1.0532 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 457us/step - loss: 1.0897 - acc: 0.4225 - val_loss: 1.0718 - val_acc: 0.8056\n",
      "5264.165122706624\n",
      "!!!!!!!!!  490  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 177ms/step - loss: 1.0969 - acc: 0.2394 - val_loss: 1.0952 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 477us/step - loss: 1.0777 - acc: 0.5211 - val_loss: 1.1027 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 178ms/step - loss: 1.1204 - acc: 0.1056 - val_loss: 1.0989 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 492us/step - loss: 1.0918 - acc: 0.3380 - val_loss: 1.1149 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 25s 177ms/step - loss: 1.1500 - acc: 0.4577 - val_loss: 1.0992 - val_acc: 0.1944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 477us/step - loss: 1.1332 - acc: 0.4437 - val_loss: 1.1120 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 26s 182ms/step - loss: 1.0772 - acc: 0.6408 - val_loss: 1.1386 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 478us/step - loss: 1.0636 - acc: 0.7042 - val_loss: 1.1475 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 26s 180ms/step - loss: 0.9970 - acc: 0.5070 - val_loss: 1.2570 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 520us/step - loss: 0.9703 - acc: 0.5352 - val_loss: 1.2826 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 26s 182ms/step - loss: 1.1624 - acc: 0.0915 - val_loss: 1.1025 - val_acc: 0.3056\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 499us/step - loss: 1.1371 - acc: 0.0634 - val_loss: 1.1175 - val_acc: 0.0556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 26s 181ms/step - loss: 1.0175 - acc: 0.4718 - val_loss: 1.1751 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 505us/step - loss: 0.9973 - acc: 0.5211 - val_loss: 1.1920 - val_acc: 0.0000e+00\n",
      "5446.26865050611\n",
      "!!!!!!!!!  500  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 26s 184ms/step - loss: 1.0679 - acc: 0.4718 - val_loss: 1.1118 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 492us/step - loss: 1.0461 - acc: 0.5493 - val_loss: 1.1282 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 187ms/step - loss: 1.0987 - acc: 0.1338 - val_loss: 1.0711 - val_acc: 0.3611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 485us/step - loss: 1.0852 - acc: 0.3028 - val_loss: 1.0854 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 187ms/step - loss: 1.0616 - acc: 0.5000 - val_loss: 1.1902 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 492us/step - loss: 1.0450 - acc: 0.5000 - val_loss: 1.2159 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 189ms/step - loss: 1.0972 - acc: 0.2465 - val_loss: 1.1368 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 421us/step - loss: 1.0703 - acc: 0.4014 - val_loss: 1.1602 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 26s 186ms/step - loss: 1.1911 - acc: 0.0845 - val_loss: 1.0494 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 485us/step - loss: 1.1663 - acc: 0.0915 - val_loss: 1.0612 - val_acc: 0.8611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 189ms/step - loss: 1.1767 - acc: 0.0775 - val_loss: 1.0588 - val_acc: 0.6389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 464us/step - loss: 1.1544 - acc: 0.1690 - val_loss: 1.0726 - val_acc: 0.2778\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 189ms/step - loss: 1.1518 - acc: 0.2394 - val_loss: 1.1111 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 513us/step - loss: 1.1300 - acc: 0.3873 - val_loss: 1.1272 - val_acc: 0.0000e+00\n",
      "5636.123972764844\n",
      "!!!!!!!!!  510  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 190ms/step - loss: 1.1326 - acc: 0.0845 - val_loss: 1.0567 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 730us/step - loss: 1.1134 - acc: 0.0775 - val_loss: 1.0733 - val_acc: 0.7500\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 28s 194ms/step - loss: 1.1510 - acc: 0.2113 - val_loss: 1.0604 - val_acc: 0.7222\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 485us/step - loss: 1.1393 - acc: 0.3028 - val_loss: 1.0672 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 28s 194ms/step - loss: 1.0474 - acc: 0.4930 - val_loss: 1.0958 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 506us/step - loss: 1.0299 - acc: 0.5000 - val_loss: 1.1023 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 27s 193ms/step - loss: 1.1449 - acc: 0.0775 - val_loss: 0.9272 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 435us/step - loss: 1.1266 - acc: 0.1127 - val_loss: 0.9358 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 28s 194ms/step - loss: 1.1008 - acc: 0.1197 - val_loss: 1.0735 - val_acc: 0.6389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 435us/step - loss: 1.0835 - acc: 0.4718 - val_loss: 1.0752 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 28s 195ms/step - loss: 1.0682 - acc: 0.4930 - val_loss: 1.1227 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 478us/step - loss: 1.0497 - acc: 0.5000 - val_loss: 1.1343 - val_acc: 0.0000e+00\n",
      "5804.138588814565\n",
      "!!!!!!!!!  520  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 28s 198ms/step - loss: 1.0796 - acc: 0.4718 - val_loss: 1.2426 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 450us/step - loss: 1.0662 - acc: 0.4789 - val_loss: 1.2380 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 28s 199ms/step - loss: 1.0760 - acc: 0.4507 - val_loss: 1.1238 - val_acc: 0.2778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 513us/step - loss: 1.0475 - acc: 0.4577 - val_loss: 1.1261 - val_acc: 0.3611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 28s 200ms/step - loss: 1.1038 - acc: 0.2958 - val_loss: 1.3554 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 457us/step - loss: 1.0893 - acc: 0.3662 - val_loss: 1.3354 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 30s 214ms/step - loss: 1.1173 - acc: 0.0211 - val_loss: 1.0843 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 604us/step - loss: 1.1005 - acc: 0.2817 - val_loss: 1.0853 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 32s 226ms/step - loss: 1.0960 - acc: 0.4789 - val_loss: 1.1122 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 527us/step - loss: 1.0685 - acc: 0.5000 - val_loss: 1.1187 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 34s 236ms/step - loss: 1.0846 - acc: 0.2465 - val_loss: 1.0979 - val_acc: 0.1389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 604us/step - loss: 1.0657 - acc: 0.2676 - val_loss: 1.0983 - val_acc: 0.1944\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 31s 220ms/step - loss: 1.0783 - acc: 0.5000 - val_loss: 1.2561 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 597us/step - loss: 1.0550 - acc: 0.5000 - val_loss: 1.2575 - val_acc: 0.0000e+00\n",
      "6020.073137866764\n",
      "!!!!!!!!!  530  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 33s 229ms/step - loss: 1.0498 - acc: 0.5282 - val_loss: 1.1880 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 639us/step - loss: 1.0274 - acc: 0.5493 - val_loss: 1.1902 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 31s 218ms/step - loss: 1.0501 - acc: 0.4155 - val_loss: 1.2324 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 548us/step - loss: 1.0303 - acc: 0.4155 - val_loss: 1.2291 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 35s 244ms/step - loss: 1.0940 - acc: 0.4155 - val_loss: 1.0780 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 626us/step - loss: 1.0779 - acc: 0.4155 - val_loss: 1.0551 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 32s 223ms/step - loss: 1.1054 - acc: 0.1761 - val_loss: 0.9875 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 555us/step - loss: 1.0850 - acc: 0.2676 - val_loss: 0.9781 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 31s 216ms/step - loss: 1.0825 - acc: 0.5000 - val_loss: 1.2160 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 555us/step - loss: 1.0555 - acc: 0.6338 - val_loss: 1.2314 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 31s 221ms/step - loss: 1.1865 - acc: 0.0845 - val_loss: 1.0148 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 555us/step - loss: 1.1567 - acc: 0.0986 - val_loss: 1.0215 - val_acc: 1.0000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 31s 219ms/step - loss: 1.1191 - acc: 0.2535 - val_loss: 0.9643 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 534us/step - loss: 1.0944 - acc: 0.5704 - val_loss: 0.9474 - val_acc: 1.0000\n",
      "6247.1353946534\n",
      "!!!!!!!!!  540  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 33s 230ms/step - loss: 1.1306 - acc: 0.0915 - val_loss: 1.0583 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 696us/step - loss: 1.1071 - acc: 0.3310 - val_loss: 1.0582 - val_acc: 0.0556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 31s 221ms/step - loss: 1.0660 - acc: 0.3521 - val_loss: 1.2144 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 485us/step - loss: 1.0469 - acc: 0.4014 - val_loss: 1.2080 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 31s 217ms/step - loss: 1.1318 - acc: 0.0845 - val_loss: 0.8898 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 506us/step - loss: 1.1096 - acc: 0.0915 - val_loss: 0.8749 - val_acc: 1.0000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 30s 214ms/step - loss: 1.1621 - acc: 0.0070 - val_loss: 1.1167 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 563us/step - loss: 1.1437 - acc: 0.0282 - val_loss: 1.1164 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 34s 240ms/step - loss: 1.0947 - acc: 0.2113 - val_loss: 1.0764 - val_acc: 0.5278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 527us/step - loss: 1.0677 - acc: 0.4155 - val_loss: 1.0690 - val_acc: 0.6667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 33s 229ms/step - loss: 1.1222 - acc: 0.3451 - val_loss: 1.2296 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 513us/step - loss: 1.0950 - acc: 0.4437 - val_loss: 1.2164 - val_acc: 0.0000e+00\n",
      "6442.298901134166\n",
      "!!!!!!!!!  550  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 32s 228ms/step - loss: 1.0059 - acc: 0.5282 - val_loss: 1.0394 - val_acc: 0.8889\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 548us/step - loss: 0.9808 - acc: 0.6197 - val_loss: 1.0234 - val_acc: 0.8889\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 33s 229ms/step - loss: 1.0597 - acc: 0.4859 - val_loss: 1.2126 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 527us/step - loss: 1.0293 - acc: 0.5000 - val_loss: 1.2079 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 32s 226ms/step - loss: 1.1217 - acc: 0.1831 - val_loss: 1.1348 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 471us/step - loss: 1.0882 - acc: 0.3662 - val_loss: 1.1212 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 33s 231ms/step - loss: 1.0207 - acc: 0.6408 - val_loss: 1.0947 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 477us/step - loss: 0.9959 - acc: 0.6831 - val_loss: 1.0919 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 34s 238ms/step - loss: 1.0459 - acc: 0.7324 - val_loss: 1.1444 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 590us/step - loss: 1.0219 - acc: 0.7958 - val_loss: 1.1523 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 37s 261ms/step - loss: 1.0694 - acc: 0.5211 - val_loss: 1.1742 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 752us/step - loss: 1.0503 - acc: 0.7324 - val_loss: 1.1645 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 37s 264ms/step - loss: 1.0428 - acc: 0.6056 - val_loss: 0.9825 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 723us/step - loss: 1.0189 - acc: 0.6831 - val_loss: 0.9788 - val_acc: 0.9722\n",
      "6684.666114431854\n",
      "!!!!!!!!!  560  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 41s 288ms/step - loss: 1.2054 - acc: 0.0211 - val_loss: 1.1184 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 653us/step - loss: 1.1725 - acc: 0.0634 - val_loss: 1.1222 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 39s 278ms/step - loss: 1.1166 - acc: 0.1831 - val_loss: 1.0128 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 611us/step - loss: 1.0844 - acc: 0.4014 - val_loss: 1.0146 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 37s 260ms/step - loss: 1.0824 - acc: 0.5000 - val_loss: 1.0588 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 625us/step - loss: 1.0562 - acc: 0.4930 - val_loss: 1.0609 - val_acc: 0.3611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 38s 269ms/step - loss: 1.0686 - acc: 0.3803 - val_loss: 1.1052 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 744us/step - loss: 1.0491 - acc: 0.4155 - val_loss: 1.0986 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 43s 300ms/step - loss: 1.1213 - acc: 0.2535 - val_loss: 1.0867 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 850us/step - loss: 1.1029 - acc: 0.4930 - val_loss: 1.0911 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 40s 283ms/step - loss: 1.0800 - acc: 0.4648 - val_loss: 1.0148 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 716us/step - loss: 1.0584 - acc: 0.7394 - val_loss: 1.0155 - val_acc: 0.9722\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 37s 259ms/step - loss: 1.0674 - acc: 0.4155 - val_loss: 1.0906 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 1.0475 - acc: 0.4366 - val_loss: 1.0986 - val_acc: 0.0000e+00\n",
      "6964.898423924519\n",
      "!!!!!!!!!  570  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 3694s 26s/step - loss: 1.0548 - acc: 0.5211 - val_loss: 1.0957 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 780us/step - loss: 1.0368 - acc: 0.6127 - val_loss: 1.0959 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 52s 369ms/step - loss: 1.0810 - acc: 0.4296 - val_loss: 1.0894 - val_acc: 0.1944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 871us/step - loss: 1.0593 - acc: 0.6197 - val_loss: 1.0951 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 57s 403ms/step - loss: 1.1460 - acc: 0.0915 - val_loss: 0.8879 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1196 - acc: 0.1338 - val_loss: 0.8916 - val_acc: 1.0000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 59s 418ms/step - loss: 1.1023 - acc: 0.2958 - val_loss: 1.0677 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 924us/step - loss: 1.0831 - acc: 0.4507 - val_loss: 1.0751 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 57s 399ms/step - loss: 1.1271 - acc: 0.5070 - val_loss: 1.0434 - val_acc: 0.6944\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 836us/step - loss: 1.1067 - acc: 0.5141 - val_loss: 1.0455 - val_acc: 0.5278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 58s 409ms/step - loss: 1.0550 - acc: 0.5352 - val_loss: 1.1478 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0204 - acc: 0.5563 - val_loss: 1.1624 - val_acc: 0.0000e+00\n",
      "10949.497163399632\n",
      "!!!!!!!!!  580  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 61s 431ms/step - loss: 1.1095 - acc: 0.1338 - val_loss: 1.1131 - val_acc: 0.1389\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0936 - acc: 0.4577 - val_loss: 1.1197 - val_acc: 0.1111\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 61s 431ms/step - loss: 1.1265 - acc: 0.1338 - val_loss: 1.0734 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1123 - acc: 0.1761 - val_loss: 1.0857 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 60s 425ms/step - loss: 1.1428 - acc: 0.1761 - val_loss: 1.0832 - val_acc: 0.3056\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1201 - acc: 0.3873 - val_loss: 1.0946 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 62s 435ms/step - loss: 1.0814 - acc: 0.4366 - val_loss: 1.1297 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 844us/step - loss: 1.0623 - acc: 0.5211 - val_loss: 1.1422 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 59s 415ms/step - loss: 1.1388 - acc: 0.4296 - val_loss: 1.1355 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 829us/step - loss: 1.1188 - acc: 0.4437 - val_loss: 1.1486 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 59s 419ms/step - loss: 1.1045 - acc: 0.2183 - val_loss: 1.0922 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 906us/step - loss: 1.0871 - acc: 0.3028 - val_loss: 1.1076 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 64s 449ms/step - loss: 1.0667 - acc: 0.4648 - val_loss: 1.0858 - val_acc: 0.3333\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0460 - acc: 0.4930 - val_loss: 1.1079 - val_acc: 0.1667\n",
      "11382.798449488018\n",
      "!!!!!!!!!  590  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 62s 438ms/step - loss: 1.1404 - acc: 0.1831 - val_loss: 1.0864 - val_acc: 0.2222\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1206 - acc: 0.2254 - val_loss: 1.1068 - val_acc: 0.1944\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 1.1115 - acc: 0.2817 - val_loss: 1.0599 - val_acc: 0.1667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 972us/step - loss: 1.0937 - acc: 0.4507 - val_loss: 1.0777 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 62s 439ms/step - loss: 1.0854 - acc: 0.3169 - val_loss: 1.0429 - val_acc: 0.7778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0701 - acc: 0.4366 - val_loss: 1.0653 - val_acc: 0.4444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 60s 425ms/step - loss: 1.1019 - acc: 0.3310 - val_loss: 1.1402 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0850 - acc: 0.5211 - val_loss: 1.1556 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 59s 415ms/step - loss: 1.0987 - acc: 0.1408 - val_loss: 1.1197 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0820 - acc: 0.4648 - val_loss: 1.1341 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 59s 416ms/step - loss: 1.0712 - acc: 0.4718 - val_loss: 1.0901 - val_acc: 0.2778\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0537 - acc: 0.6197 - val_loss: 1.1082 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 66s 466ms/step - loss: 1.0966 - acc: 0.2887 - val_loss: 1.1300 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0793 - acc: 0.5352 - val_loss: 1.1509 - val_acc: 0.0000e+00\n",
      "11821.708294207077\n",
      "!!!!!!!!!  600  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 1.1291 - acc: 0.2113 - val_loss: 1.0808 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1096 - acc: 0.4366 - val_loss: 1.0949 - val_acc: 0.0556\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 68s 477ms/step - loss: 1.1159 - acc: 0.2817 - val_loss: 1.1548 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0959 - acc: 0.3803 - val_loss: 1.1700 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 64s 448ms/step - loss: 1.0992 - acc: 0.4155 - val_loss: 1.1033 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0804 - acc: 0.4155 - val_loss: 1.1226 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 61s 431ms/step - loss: 1.0692 - acc: 0.5000 - val_loss: 1.1280 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 871us/step - loss: 1.0464 - acc: 0.5070 - val_loss: 1.1511 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 63s 443ms/step - loss: 1.0911 - acc: 0.4155 - val_loss: 1.1307 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0733 - acc: 0.4155 - val_loss: 1.1414 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 68s 476ms/step - loss: 1.1040 - acc: 0.2183 - val_loss: 1.1065 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 866us/step - loss: 1.0847 - acc: 0.5000 - val_loss: 1.1141 - val_acc: 0.0000e+00\n",
      "12213.760393422632\n",
      "!!!!!!!!!  610  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 62s 439ms/step - loss: 1.0968 - acc: 0.4366 - val_loss: 1.1192 - val_acc: 0.1667\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 879us/step - loss: 1.0709 - acc: 0.5000 - val_loss: 1.1395 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 64s 453ms/step - loss: 1.0399 - acc: 0.5986 - val_loss: 1.1660 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 952us/step - loss: 1.0224 - acc: 0.7958 - val_loss: 1.1821 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 64s 449ms/step - loss: 1.0801 - acc: 0.5000 - val_loss: 1.1478 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0589 - acc: 0.6127 - val_loss: 1.1704 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 64s 448ms/step - loss: 1.0482 - acc: 0.4930 - val_loss: 1.1680 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0213 - acc: 0.5000 - val_loss: 1.1974 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 66s 463ms/step - loss: 1.0625 - acc: 0.4930 - val_loss: 1.0682 - val_acc: 0.5556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0394 - acc: 0.5563 - val_loss: 1.0915 - val_acc: 0.4167\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 69s 483ms/step - loss: 1.0947 - acc: 0.2887 - val_loss: 1.1231 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0751 - acc: 0.4577 - val_loss: 1.1396 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 65s 455ms/step - loss: 1.0861 - acc: 0.3944 - val_loss: 1.1152 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0592 - acc: 0.5493 - val_loss: 1.1295 - val_acc: 0.1944\n",
      "12673.8693096141\n",
      "!!!!!!!!!  620  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 65s 456ms/step - loss: 1.0644 - acc: 0.6197 - val_loss: 1.1752 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0417 - acc: 0.6972 - val_loss: 1.1935 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 69s 485ms/step - loss: 1.0633 - acc: 0.5000 - val_loss: 1.1394 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0435 - acc: 0.6197 - val_loss: 1.1603 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 70s 491ms/step - loss: 1.1072 - acc: 0.2887 - val_loss: 1.1135 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0873 - acc: 0.4507 - val_loss: 1.1351 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 74s 522ms/step - loss: 1.0872 - acc: 0.3239 - val_loss: 1.1049 - val_acc: 0.4167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0670 - acc: 0.6127 - val_loss: 1.1271 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 73s 511ms/step - loss: 1.0601 - acc: 0.7183 - val_loss: 1.1497 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0347 - acc: 0.8380 - val_loss: 1.1829 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 70s 490ms/step - loss: 1.0948 - acc: 0.2817 - val_loss: 1.1575 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0718 - acc: 0.4296 - val_loss: 1.1775 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 69s 488ms/step - loss: 1.1485 - acc: 0.0845 - val_loss: 1.0334 - val_acc: 0.9444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1265 - acc: 0.1197 - val_loss: 1.0599 - val_acc: 0.8056\n",
      "13170.111607470084\n",
      "!!!!!!!!!  630  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 67s 468ms/step - loss: 1.1561 - acc: 0.0845 - val_loss: 1.0448 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1328 - acc: 0.1056 - val_loss: 1.0723 - val_acc: 0.6389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 68s 477ms/step - loss: 1.1004 - acc: 0.2254 - val_loss: 1.1323 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 916us/step - loss: 1.0758 - acc: 0.3873 - val_loss: 1.1578 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 68s 481ms/step - loss: 1.1169 - acc: 0.2324 - val_loss: 1.1756 - val_acc: 0.0278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0822 - acc: 0.3592 - val_loss: 1.2071 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 73s 512ms/step - loss: 1.1240 - acc: 0.0915 - val_loss: 1.0697 - val_acc: 0.4722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.1012 - acc: 0.2535 - val_loss: 1.0977 - val_acc: 0.2222\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 78s 547ms/step - loss: 1.0769 - acc: 0.4155 - val_loss: 1.1166 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0538 - acc: 0.4155 - val_loss: 1.1377 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 71s 500ms/step - loss: 1.0551 - acc: 0.5282 - val_loss: 1.1943 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0345 - acc: 0.7465 - val_loss: 1.2132 - val_acc: 0.0000e+00\n",
      "13600.460514238432\n",
      "!!!!!!!!!  640  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 77s 540ms/step - loss: 1.1082 - acc: 0.2254 - val_loss: 1.0699 - val_acc: 0.5278\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 955us/step - loss: 1.0787 - acc: 0.3521 - val_loss: 1.1027 - val_acc: 0.4167\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 70s 492ms/step - loss: 1.0735 - acc: 0.5000 - val_loss: 1.1616 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0610 - acc: 0.5000 - val_loss: 1.1893 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 71s 498ms/step - loss: 1.1050 - acc: 0.0986 - val_loss: 1.1445 - val_acc: 0.0833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0794 - acc: 0.2535 - val_loss: 1.1668 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 70s 494ms/step - loss: 1.1061 - acc: 0.4225 - val_loss: 1.0985 - val_acc: 0.3611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0805 - acc: 0.4859 - val_loss: 1.1164 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 71s 502ms/step - loss: 1.1195 - acc: 0.0915 - val_loss: 1.0704 - val_acc: 0.5833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 991us/step - loss: 1.0890 - acc: 0.4014 - val_loss: 1.1016 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 69s 486ms/step - loss: 1.0876 - acc: 0.0634 - val_loss: 1.2576 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 860us/step - loss: 1.0613 - acc: 0.2254 - val_loss: 1.2861 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 71s 497ms/step - loss: 1.1352 - acc: 0.0915 - val_loss: 1.0041 - val_acc: 0.9444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.1075 - acc: 0.1338 - val_loss: 1.0291 - val_acc: 0.8056\n",
      "14105.540979092995\n",
      "!!!!!!!!!  650  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 75s 529ms/step - loss: 1.1018 - acc: 0.2817 - val_loss: 1.1015 - val_acc: 0.5833\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0855 - acc: 0.4930 - val_loss: 1.1197 - val_acc: 0.1389\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 76s 536ms/step - loss: 1.1214 - acc: 0.4296 - val_loss: 1.0766 - val_acc: 0.4444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0976 - acc: 0.4789 - val_loss: 1.1021 - val_acc: 0.2222\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 76s 537ms/step - loss: 1.1197 - acc: 0.1056 - val_loss: 0.9589 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0882 - acc: 0.1690 - val_loss: 0.9854 - val_acc: 0.8611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 77s 539ms/step - loss: 1.0804 - acc: 0.4718 - val_loss: 1.1667 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 899us/step - loss: 1.0651 - acc: 0.6972 - val_loss: 1.1906 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 77s 543ms/step - loss: 1.0494 - acc: 0.8169 - val_loss: 1.1543 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0303 - acc: 0.8239 - val_loss: 1.1777 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 75s 528ms/step - loss: 1.0931 - acc: 0.5775 - val_loss: 1.1154 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0725 - acc: 0.6338 - val_loss: 1.1271 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 77s 544ms/step - loss: 1.1348 - acc: 0.2113 - val_loss: 0.9671 - val_acc: 0.9444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1149 - acc: 0.2535 - val_loss: 0.9976 - val_acc: 0.9167\n",
      "14646.617711165998\n",
      "!!!!!!!!!  660  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 75s 527ms/step - loss: 1.0676 - acc: 0.4155 - val_loss: 1.0686 - val_acc: 0.4167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0445 - acc: 0.6620 - val_loss: 1.0871 - val_acc: 0.0833\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 76s 533ms/step - loss: 1.0023 - acc: 0.7254 - val_loss: 1.4417 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.9794 - acc: 0.7394 - val_loss: 1.4796 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 75s 526ms/step - loss: 1.0152 - acc: 0.7958 - val_loss: 1.2659 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 0.9938 - acc: 0.8028 - val_loss: 1.2901 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 76s 533ms/step - loss: 1.0615 - acc: 0.4366 - val_loss: 1.1475 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0449 - acc: 0.4859 - val_loss: 1.1663 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 77s 540ms/step - loss: 1.1238 - acc: 0.1620 - val_loss: 0.9553 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.1036 - acc: 0.2113 - val_loss: 0.9839 - val_acc: 0.8611\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 77s 539ms/step - loss: 1.1052 - acc: 0.1972 - val_loss: 1.1060 - val_acc: 0.3333\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0917 - acc: 0.2817 - val_loss: 1.1272 - val_acc: 0.0000e+00\n",
      "15107.3057358149\n",
      "!!!!!!!!!  670  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 77s 542ms/step - loss: 1.0793 - acc: 0.6056 - val_loss: 1.1689 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0613 - acc: 0.6338 - val_loss: 1.1829 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 63s 444ms/step - loss: 1.0836 - acc: 0.1761 - val_loss: 1.1986 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 678us/step - loss: 1.0681 - acc: 0.4859 - val_loss: 1.2335 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 51s 358ms/step - loss: 1.0459 - acc: 0.7465 - val_loss: 1.1589 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 674us/step - loss: 1.0267 - acc: 0.7676 - val_loss: 1.1953 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 50s 352ms/step - loss: 1.0888 - acc: 0.4437 - val_loss: 1.2128 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 583us/step - loss: 1.0768 - acc: 0.6831 - val_loss: 1.2348 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 52s 365ms/step - loss: 1.0687 - acc: 0.5070 - val_loss: 1.1001 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 674us/step - loss: 1.0560 - acc: 0.5211 - val_loss: 1.1164 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 60s 422ms/step - loss: 1.1237 - acc: 0.4577 - val_loss: 1.0913 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 815us/step - loss: 1.1019 - acc: 0.4930 - val_loss: 1.1177 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 55s 387ms/step - loss: 1.0880 - acc: 0.5775 - val_loss: 1.1533 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 850us/step - loss: 1.0714 - acc: 0.6901 - val_loss: 1.1768 - val_acc: 0.0000e+00\n",
      "15519.819188014255\n",
      "!!!!!!!!!  680  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 15570s 110s/step - loss: 1.1142 - acc: 0.2324 - val_loss: 1.0838 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 766us/step - loss: 1.0951 - acc: 0.3662 - val_loss: 1.1298 - val_acc: 0.0278\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 60s 419ms/step - loss: 1.0639 - acc: 0.4789 - val_loss: 1.2271 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 752us/step - loss: 1.0455 - acc: 0.6690 - val_loss: 1.2541 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 81s 574ms/step - loss: 1.1115 - acc: 0.2676 - val_loss: 1.0717 - val_acc: 0.9167\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0946 - acc: 0.4296 - val_loss: 1.1019 - val_acc: 0.3333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 81s 571ms/step - loss: 1.1068 - acc: 0.3028 - val_loss: 1.0174 - val_acc: 0.9722\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0918 - acc: 0.4648 - val_loss: 1.0415 - val_acc: 0.9444\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 82s 577ms/step - loss: 1.1022 - acc: 0.3099 - val_loss: 1.1586 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0886 - acc: 0.3169 - val_loss: 1.1776 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 82s 580ms/step - loss: 1.1006 - acc: 0.2535 - val_loss: 1.1829 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0885 - acc: 0.4437 - val_loss: 1.1909 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 82s 579ms/step - loss: 1.0988 - acc: 0.3803 - val_loss: 1.1738 - val_acc: 0.0556\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0817 - acc: 0.4930 - val_loss: 1.1897 - val_acc: 0.0556\n",
      "31568.62904990936\n",
      "!!!!!!!!!  690  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 80s 566ms/step - loss: 1.0759 - acc: 0.3451 - val_loss: 0.9706 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0607 - acc: 0.5070 - val_loss: 1.0043 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 82s 575ms/step - loss: 1.0703 - acc: 0.4366 - val_loss: 1.4536 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0612 - acc: 0.4859 - val_loss: 1.4797 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 86s 608ms/step - loss: 1.0963 - acc: 0.4014 - val_loss: 1.2892 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0805 - acc: 0.4648 - val_loss: 1.3101 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 84s 593ms/step - loss: 1.0718 - acc: 0.5282 - val_loss: 1.2170 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0578 - acc: 0.5423 - val_loss: 1.2494 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 85s 600ms/step - loss: 1.1120 - acc: 0.1761 - val_loss: 1.0464 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0967 - acc: 0.3803 - val_loss: 1.0677 - val_acc: 0.8333\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 83s 585ms/step - loss: 1.0962 - acc: 0.3310 - val_loss: 1.3382 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0805 - acc: 0.4014 - val_loss: 1.3777 - val_acc: 0.0000e+00\n",
      "32075.40641115079\n",
      "!!!!!!!!!  700  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 83s 582ms/step - loss: 1.0924 - acc: 0.5352 - val_loss: 1.1477 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0799 - acc: 0.4859 - val_loss: 1.1728 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 83s 587ms/step - loss: 1.0733 - acc: 0.4789 - val_loss: 1.2198 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0621 - acc: 0.4789 - val_loss: 1.2573 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 85s 596ms/step - loss: 1.0939 - acc: 0.4507 - val_loss: 1.2514 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0826 - acc: 0.4718 - val_loss: 1.2804 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 87s 610ms/step - loss: 1.0581 - acc: 0.5000 - val_loss: 1.3835 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0476 - acc: 0.5000 - val_loss: 1.4172 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 83s 586ms/step - loss: 1.1330 - acc: 0.4225 - val_loss: 1.0974 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1178 - acc: 0.4155 - val_loss: 1.1249 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 86s 605ms/step - loss: 1.1010 - acc: 0.2465 - val_loss: 1.0446 - val_acc: 0.8056\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.0913 - acc: 0.3732 - val_loss: 1.0615 - val_acc: 0.3056\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 85s 596ms/step - loss: 1.0997 - acc: 0.4225 - val_loss: 1.1399 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0872 - acc: 0.3803 - val_loss: 1.1781 - val_acc: 0.0000e+00\n",
      "32673.45441984165\n",
      "!!!!!!!!!  710  !!!!!!!!\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 85s 597ms/step - loss: 1.0856 - acc: 0.4789 - val_loss: 1.1088 - val_acc: 0.3056\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0706 - acc: 0.5423 - val_loss: 1.1550 - val_acc: 0.1667\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 85s 599ms/step - loss: 1.0795 - acc: 0.3873 - val_loss: 1.0815 - val_acc: 0.4444\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0679 - acc: 0.4789 - val_loss: 1.1097 - val_acc: 0.0000e+00\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 86s 606ms/step - loss: 1.0950 - acc: 0.3028 - val_loss: 1.0364 - val_acc: 0.8611\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 1.0797 - acc: 0.4296 - val_loss: 1.0723 - val_acc: 0.5000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n",
      "142/142 [==============================] - 10887s 77s/step - loss: 1.1659 - acc: 0.0986 - val_loss: 0.7928 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 1.1441 - acc: 0.1268 - val_loss: 0.8313 - val_acc: 1.0000\n",
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "for i in range(999):\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(time.clock() - start)\n",
    "        print(\"!!!!!!!!!  \" + str(i) + \"  !!!!!!!!\")\n",
    "        \n",
    "    if i % 3 == 0:\n",
    "        continue\n",
    "\n",
    "    xData = tData[i][0]\n",
    "    yData = tData[i][1]\n",
    "    trainingData = np.vstack((xData, yData)).T\n",
    "    # NN model code\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    nnet = model.fit(trainingData, targetData, epochs=2, validation_split=0.2)\n",
    "    accuracy.append(np.mean(nnet.history[\"acc\"]))\n",
    "    \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0915492961943989,\n",
       " 0.4225352129466097,\n",
       " 0.3591549302070913,\n",
       " 0.5845070426732721,\n",
       " 0.3873239424027188,\n",
       " 0.647887322264658,\n",
       " 0.3556338032366524,\n",
       " 0.4894366201380609,\n",
       " 0.5000000014691286,\n",
       " 0.6056338049156565]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.7464788736591876\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba855d9d30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = list(range(0, len(accuracy)))\n",
    "\n",
    "new = plt.figure()\n",
    "plt.plot(x, accuracy, \"-\", marker=\"None\")\n",
    "\n",
    "max_accuracy = max(accuracy)\n",
    "acc = max_accuracy\n",
    "max_accuracy = [i for i, j in enumerate(accuracy) if j == max_accuracy]\n",
    "max_accuracy = max_accuracy[0]\n",
    "print(max_accuracy, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113 samples, validate on 29 samples\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 1.1139 - acc: 0.3894 - val_loss: 1.1106 - val_acc: 0.3448\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.1048 - acc: 0.3628 - val_loss: 1.1020 - val_acc: 0.3448\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0962 - acc: 0.3628 - val_loss: 1.0947 - val_acc: 0.3448\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0903 - acc: 0.3628 - val_loss: 1.0901 - val_acc: 0.3448\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0863 - acc: 0.3628 - val_loss: 1.0866 - val_acc: 0.3448\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0829 - acc: 0.3628 - val_loss: 1.0832 - val_acc: 0.3448\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0800 - acc: 0.3628 - val_loss: 1.0803 - val_acc: 0.3448\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0776 - acc: 0.3628 - val_loss: 1.0771 - val_acc: 0.3448\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 0s 106us/step - loss: 1.0745 - acc: 0.3628 - val_loss: 1.0743 - val_acc: 0.3448\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0716 - acc: 0.3628 - val_loss: 1.0714 - val_acc: 0.3448\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0688 - acc: 0.3628 - val_loss: 1.0686 - val_acc: 0.3448\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0668 - acc: 0.3628 - val_loss: 1.0658 - val_acc: 0.3448\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0639 - acc: 0.3894 - val_loss: 1.0631 - val_acc: 0.3448\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0614 - acc: 0.3982 - val_loss: 1.0600 - val_acc: 0.3448\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0587 - acc: 0.3982 - val_loss: 1.0566 - val_acc: 0.3448\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0562 - acc: 0.4071 - val_loss: 1.0530 - val_acc: 0.3448\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0541 - acc: 0.4071 - val_loss: 1.0492 - val_acc: 0.3448\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0515 - acc: 0.4159 - val_loss: 1.0457 - val_acc: 0.3793\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0486 - acc: 0.4159 - val_loss: 1.0417 - val_acc: 0.4138\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0462 - acc: 0.4159 - val_loss: 1.0377 - val_acc: 0.4138\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0431 - acc: 0.3894 - val_loss: 1.0340 - val_acc: 0.4138\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 1.0401 - acc: 0.3982 - val_loss: 1.0296 - val_acc: 0.4138\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0370 - acc: 0.3982 - val_loss: 1.0244 - val_acc: 0.4138\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0335 - acc: 0.4159 - val_loss: 1.0188 - val_acc: 0.4138\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0302 - acc: 0.4159 - val_loss: 1.0135 - val_acc: 0.4138\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0261 - acc: 0.4248 - val_loss: 1.0079 - val_acc: 0.4138\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0224 - acc: 0.4336 - val_loss: 1.0015 - val_acc: 0.4483\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 1.0181 - acc: 0.4336 - val_loss: 0.9957 - val_acc: 0.4138\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0145 - acc: 0.4425 - val_loss: 0.9894 - val_acc: 0.4138\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0102 - acc: 0.4425 - val_loss: 0.9834 - val_acc: 0.4138\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 1.0071 - acc: 0.4602 - val_loss: 0.9780 - val_acc: 0.4138\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 1.0026 - acc: 0.4602 - val_loss: 0.9723 - val_acc: 0.4138\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9986 - acc: 0.4602 - val_loss: 0.9662 - val_acc: 0.4828\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9945 - acc: 0.4425 - val_loss: 0.9604 - val_acc: 0.4828\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9906 - acc: 0.4602 - val_loss: 0.9536 - val_acc: 0.4828\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9863 - acc: 0.4602 - val_loss: 0.9481 - val_acc: 0.4828\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9827 - acc: 0.4602 - val_loss: 0.9423 - val_acc: 0.4828\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9792 - acc: 0.4602 - val_loss: 0.9368 - val_acc: 0.4828\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 0s 106us/step - loss: 0.9756 - acc: 0.4602 - val_loss: 0.9317 - val_acc: 0.4828\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9727 - acc: 0.4690 - val_loss: 0.9265 - val_acc: 0.4828\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9695 - acc: 0.4690 - val_loss: 0.9217 - val_acc: 0.4828\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9659 - acc: 0.4602 - val_loss: 0.9180 - val_acc: 0.4828\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9628 - acc: 0.4779 - val_loss: 0.9149 - val_acc: 0.4828\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9601 - acc: 0.4867 - val_loss: 0.9112 - val_acc: 0.4828\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9571 - acc: 0.4779 - val_loss: 0.9078 - val_acc: 0.5172\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9543 - acc: 0.4867 - val_loss: 0.9049 - val_acc: 0.5172\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9522 - acc: 0.5133 - val_loss: 0.9015 - val_acc: 0.5517\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9492 - acc: 0.5133 - val_loss: 0.8988 - val_acc: 0.5517\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9473 - acc: 0.5133 - val_loss: 0.8957 - val_acc: 0.5517\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9443 - acc: 0.5221 - val_loss: 0.8940 - val_acc: 0.5517\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9419 - acc: 0.5221 - val_loss: 0.8923 - val_acc: 0.5517\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9398 - acc: 0.5221 - val_loss: 0.8902 - val_acc: 0.5517\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9374 - acc: 0.5133 - val_loss: 0.8886 - val_acc: 0.5517\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9350 - acc: 0.5221 - val_loss: 0.8870 - val_acc: 0.5862\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9333 - acc: 0.5310 - val_loss: 0.8857 - val_acc: 0.5862\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9316 - acc: 0.5398 - val_loss: 0.8837 - val_acc: 0.5862\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9294 - acc: 0.5398 - val_loss: 0.8821 - val_acc: 0.5862\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9276 - acc: 0.5487 - val_loss: 0.8807 - val_acc: 0.5862\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9259 - acc: 0.5487 - val_loss: 0.8798 - val_acc: 0.5862\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9249 - acc: 0.5487 - val_loss: 0.8793 - val_acc: 0.5862\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 0s 106us/step - loss: 0.9226 - acc: 0.5398 - val_loss: 0.8780 - val_acc: 0.5862\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9209 - acc: 0.5487 - val_loss: 0.8765 - val_acc: 0.5862\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9198 - acc: 0.5487 - val_loss: 0.8758 - val_acc: 0.5862\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9184 - acc: 0.5575 - val_loss: 0.8739 - val_acc: 0.5862\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9166 - acc: 0.5664 - val_loss: 0.8726 - val_acc: 0.6207\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9152 - acc: 0.5752 - val_loss: 0.8716 - val_acc: 0.6207\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.9141 - acc: 0.5664 - val_loss: 0.8706 - val_acc: 0.6552\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9129 - acc: 0.5664 - val_loss: 0.8700 - val_acc: 0.6552\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9119 - acc: 0.5929 - val_loss: 0.8700 - val_acc: 0.6897\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9107 - acc: 0.6106 - val_loss: 0.8693 - val_acc: 0.7241\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9098 - acc: 0.6637 - val_loss: 0.8688 - val_acc: 0.7241\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9085 - acc: 0.7345 - val_loss: 0.8683 - val_acc: 0.7586\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9075 - acc: 0.7434 - val_loss: 0.8680 - val_acc: 0.7586\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9064 - acc: 0.7345 - val_loss: 0.8675 - val_acc: 0.7586\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9050 - acc: 0.7434 - val_loss: 0.8668 - val_acc: 0.7586\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9040 - acc: 0.7611 - val_loss: 0.8659 - val_acc: 0.7586\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.9030 - acc: 0.7522 - val_loss: 0.8654 - val_acc: 0.7586\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.9021 - acc: 0.7522 - val_loss: 0.8647 - val_acc: 0.7586\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.9012 - acc: 0.7522 - val_loss: 0.8632 - val_acc: 0.7931\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8996 - acc: 0.7699 - val_loss: 0.8623 - val_acc: 0.7931\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.8985 - acc: 0.7699 - val_loss: 0.8619 - val_acc: 0.7586\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8969 - acc: 0.7611 - val_loss: 0.8620 - val_acc: 0.7586\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8959 - acc: 0.7080 - val_loss: 0.8612 - val_acc: 0.7586\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8951 - acc: 0.6903 - val_loss: 0.8606 - val_acc: 0.6897\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8940 - acc: 0.6903 - val_loss: 0.8596 - val_acc: 0.7241\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8931 - acc: 0.6903 - val_loss: 0.8588 - val_acc: 0.7241\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8916 - acc: 0.6903 - val_loss: 0.8581 - val_acc: 0.7586\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8901 - acc: 0.6903 - val_loss: 0.8569 - val_acc: 0.7586\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8889 - acc: 0.7168 - val_loss: 0.8561 - val_acc: 0.7586\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8875 - acc: 0.7699 - val_loss: 0.8550 - val_acc: 0.7931\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8866 - acc: 0.7699 - val_loss: 0.8540 - val_acc: 0.7931\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 0s 71us/step - loss: 0.8848 - acc: 0.7611 - val_loss: 0.8538 - val_acc: 0.7931\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8836 - acc: 0.7611 - val_loss: 0.8532 - val_acc: 0.7931\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8823 - acc: 0.7788 - val_loss: 0.8532 - val_acc: 0.7931\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8804 - acc: 0.7788 - val_loss: 0.8529 - val_acc: 0.7931\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8796 - acc: 0.7788 - val_loss: 0.8527 - val_acc: 0.7586\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 0s 88us/step - loss: 0.8778 - acc: 0.7788 - val_loss: 0.8514 - val_acc: 0.7586\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8764 - acc: 0.7788 - val_loss: 0.8499 - val_acc: 0.7931\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 0s 79us/step - loss: 0.8743 - acc: 0.7699 - val_loss: 0.8483 - val_acc: 0.7931\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 0s 97us/step - loss: 0.8735 - acc: 0.7611 - val_loss: 0.8473 - val_acc: 0.8276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3893805317646634,\n",
       " 0.36283185919829175,\n",
       " 0.3628318602532412,\n",
       " 0.3628318597257665,\n",
       " 0.3628318602532412,\n",
       " 0.362831858670817,\n",
       " 0.3628318602532412,\n",
       " 0.3628318602532412,\n",
       " 0.36283185906642307,\n",
       " 0.3628318597257665,\n",
       " 0.3628318597257665,\n",
       " 0.36283185853894834,\n",
       " 0.3893805328196129,\n",
       " 0.39823008915491864,\n",
       " 0.3982300903417368,\n",
       " 0.40707964733638596,\n",
       " 0.407079650237497,\n",
       " 0.4159292048585098,\n",
       " 0.4159292048585098,\n",
       " 0.41592920723214616,\n",
       " 0.38938053519324917,\n",
       " 0.3982300887593126,\n",
       " 0.3982300887593126,\n",
       " 0.4159292048585098,\n",
       " 0.4159292043310351,\n",
       " 0.42477876290810845,\n",
       " 0.4336283187159395,\n",
       " 0.4336283222763939,\n",
       " 0.44247787742488154,\n",
       " 0.44247787742488154,\n",
       " 0.46017699194165457,\n",
       " 0.4601769924691293,\n",
       " 0.4601769924691293,\n",
       " 0.44247788032599256,\n",
       " 0.46017699141417984,\n",
       " 0.46017699128231115,\n",
       " 0.46017699194165457,\n",
       " 0.46017699194165457,\n",
       " 0.4601769953702403,\n",
       " 0.46902654893630374,\n",
       " 0.4690265528923642,\n",
       " 0.46017699194165457,\n",
       " 0.47787610645842765,\n",
       " 0.48672566450802623,\n",
       " 0.47787610645842765,\n",
       " 0.48672566450802623,\n",
       " 0.5132743383930848,\n",
       " 0.513274339975509,\n",
       " 0.513274337074398,\n",
       " 0.5221238969701582,\n",
       " 0.5221238980251076,\n",
       " 0.5221238945965219,\n",
       " 0.5132743376018727,\n",
       " 0.5221238980251076,\n",
       " 0.5309734539648073,\n",
       " 0.5398230125418807,\n",
       " 0.5398230125418807,\n",
       " 0.5486725700640045,\n",
       " 0.5486725705914792,\n",
       " 0.5486725666354187,\n",
       " 0.5398230125418807,\n",
       " 0.5486725676903682,\n",
       " 0.5486725695365298,\n",
       " 0.5575221260037042,\n",
       " 0.5663716845807776,\n",
       " 0.575221243157851,\n",
       " 0.5663716822071413,\n",
       " 0.5663716822071413,\n",
       " 0.592920357674624,\n",
       " 0.6106194721913971,\n",
       " 0.6637168167966657,\n",
       " 0.7345132780286063,\n",
       " 0.743362833968306,\n",
       " 0.7345132769736569,\n",
       " 0.743362833968306,\n",
       " 0.7610619490125538,\n",
       " 0.7522123909629552,\n",
       " 0.7522123909629552,\n",
       " 0.7522123925453794,\n",
       " 0.7699115054797282,\n",
       " 0.7699115065346777,\n",
       " 0.7610619490125538,\n",
       " 0.7079646044072851,\n",
       " 0.6902654893630373,\n",
       " 0.6902654893630373,\n",
       " 0.6902654888355626,\n",
       " 0.6902654893630373,\n",
       " 0.6902654883080879,\n",
       " 0.716814161929409,\n",
       " 0.7699115054797282,\n",
       " 0.7699115065346777,\n",
       " 0.7610619474301296,\n",
       " 0.7610619495400285,\n",
       " 0.7787610619469026,\n",
       " 0.7787610635293268,\n",
       " 0.7787610645842763,\n",
       " 0.7787610635293268,\n",
       " 0.7787610630018521,\n",
       " 0.7699115054797282,\n",
       " 0.7610619495400285]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN model code\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(20, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "abcd = model.fit(trainingData, targetData, epochs=100, validation_split=0.2)\n",
    "\n",
    "abcd.history[\"acc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = plt.figure()\n",
    "plt.plot(x, accuracy, \"-\", marker=\"None\")\n",
    "\n",
    "\n",
    "\n",
    "max_accuracy = max(accuracy)\n",
    "acc = max_accuracy\n",
    "max_accuracy = [i for i, j in enumerate(accuracy) if j == max_accuracy]\n",
    "max_accuracy = max_accuracy[0]\n",
    "print(max_accuracy, acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
